// Generated by CoffeeScript 2.5.1
(function() {
  // RTSP/HTTP/RTMPT hybrid server

  // RTSP spec:
  //   RFC 2326  http://www.ietf.org/rfc/rfc2326.txt

  // TODO: clear old sessioncookies
  var Bits,
    CRLF_CRLF,
    DAY_NAMES,
    DEBUG_DISABLE_UDP_TRANSPORT,
    DEBUG_HTTP_TUNNEL,
    DEBUG_OUTGOING_PACKET_DATA,
    DEBUG_OUTGOING_RTCP,
    DEBUG_RTSP,
    DEBUG_RTSP_HEADERS_ONLY,
    DEFAULT_SERVER_NAME,
    ENABLE_START_PLAYING_FROM_KEYFRAME,
    MONTH_NAMES,
    RTSPClient,
    RTSPServer,
    SINGLE_NAL_UNIT_MAX_SIZE,
    Sequent,
    TAG,
    TIMESTAMP_ROUNDOFF,
    aac,
    api,
    avstreams,
    config,
    crypto,
    dgram,
    enabledFeatures,
    generateNewSessionID,
    generateRandom32,
    h264,
    http,
    logger,
    net,
    os,
    pad,
    resetStreamParams,
    rtp,
    sdp,
    url,
    zeropad;

  net = require("net");

  dgram = require("dgram");

  os = require("os");

  crypto = require("crypto");

  url = require("url");

  Sequent = require("sequent");

  rtp = require("./rtp");

  sdp = require("./sdp");

  h264 = require("./h264");

  aac = require("./aac");

  http = require("./http");

  avstreams = require("./avstreams");

  Bits = require("./bits");

  logger = require("./logger");

  config = require("./config");

  enabledFeatures = [];

  if (config.enableRTSP) {
    enabledFeatures.push("rtsp");
  }

  if (config.enableHTTP) {
    enabledFeatures.push("http");
  }

  if (config.enableRTMPT) {
    enabledFeatures.push("rtmpt");
  }

  TAG = enabledFeatures.join("/");

  // Default server name for RTSP and HTTP responses
  DEFAULT_SERVER_NAME = "node-rtsp-rtmp-server";

  // Start playing from keyframe
  ENABLE_START_PLAYING_FROM_KEYFRAME = false;

  // Maximum single NAL unit size
  SINGLE_NAL_UNIT_MAX_SIZE = 1358;

  DAY_NAMES = ["Sun", "Mon", "Tue", "Wed", "Thu", "Fri", "Sat"];

  MONTH_NAMES = [
    "Jan",
    "Feb",
    "Mar",
    "Apr",
    "May",
    "Jun",
    "Jul",
    "Aug",
    "Sep",
    "Oct",
    "Nov",
    "Dec"
  ];

  // If true, RTSP requests/response will be printed to the console
  DEBUG_RTSP = false;

  DEBUG_RTSP_HEADERS_ONLY = false;

  // If true, outgoing video/audio packets are printed to the console
  DEBUG_OUTGOING_PACKET_DATA = false;

  // If true, outgoing RTCP packets (sender reports) are printed to the console
  DEBUG_OUTGOING_RTCP = false;

  // If true, RTSP requests/responses tunneled in HTTP will be
  // printed to the console
  DEBUG_HTTP_TUNNEL = false;

  // If true, UDP transport will always be disabled and
  // clients will be forced to use TCP transport.
  DEBUG_DISABLE_UDP_TRANSPORT = false;

  // Two CRLFs
  CRLF_CRLF = [0x0d, 0x0a, 0x0d, 0x0a];

  TIMESTAMP_ROUNDOFF = 4294967296; // 32 bits

  if (DEBUG_OUTGOING_PACKET_DATA) {
    logger.enableTag("rtsp:out");
  }

  zeropad = function(columns, num) {
    num += "";
    while (num.length < columns) {
      num = "0" + num;
    }
    return num;
  };

  pad = function(digits, n) {
    n = n + "";
    while (n.length < digits) {
      n = "0" + n;
    }
    return n;
  };

  // Generate new random session ID
  // NOTE: Samsung SC-02B doesn't work with some hex string
  generateNewSessionID = function(callback) {
    var i, id, j;
    id = "";
    for (i = j = 0; j <= 7; i = ++j) {
      id += parseInt(Math.random() * 9) + 1;
    }
    return callback(null, id);
  };

  // Generate random 32 bit unsigned integer.
  // Return value is intended to be used as an SSRC identifier.
  generateRandom32 = function() {
    var md5sum, str;
    str =
      `${new Date().getTime()}${process.pid}${os.hostname()}` +
      (1 + Math.random() * 1000000000);
    md5sum = crypto.createHash("md5");
    md5sum.update(str);
    return md5sum
      .digest()
      .slice(0, 4)
      .readUInt32BE(0);
  };

  resetStreamParams = function(stream) {
    stream.rtspUploadingClient = null;
    stream.videoSequenceNumber = 0;
    stream.audioSequenceNumber = 0;
    stream.lastVideoRTPTimestamp = null;
    stream.lastAudioRTPTimestamp = null;
    stream.videoRTPTimestampInterval = Math.round(
      90000 / stream.videoFrameRate
    );
    return (stream.audioRTPTimestampInterval = stream.audioPeriodSize);
  };

  avstreams.on("update_frame_rate", function(stream, frameRate) {
    return (stream.videoRTPTimestampInterval = Math.round(90000 / frameRate));
  });

  avstreams.on("new", function(stream) {
    stream.rtspNumClients = 0;
    stream.rtspClients = {};
    return resetStreamParams(stream);
  });

  avstreams.on("reset", function(stream) {
    return resetStreamParams(stream);
  });

  RTSPServer = class RTSPServer {
    constructor(opts) {
      var ref, ref1;
      this.httpHandler = opts.httpHandler;
      this.rtmpServer = opts.rtmpServer;
      this.rtmptCallback = opts.rtmptCallback;
      this.numClients = 0;
      this.eventListeners = {};
      this.serverName =
        (ref = opts != null ? opts.serverName : void 0) != null
          ? ref
          : DEFAULT_SERVER_NAME;
      this.port =
        (ref1 = opts != null ? opts.port : void 0) != null ? ref1 : 8080;
      this.clients = {};
      this.httpSessions = {};
      this.rtspUploadingClients = {};
      this.highestClientID = 0;
      this.rtpParser = new rtp.RTPParser();
      this.rtpParser.on(
        "h264_nal_units",
        (streamId, nalUnits, rtpTimestamp) => {
          var calculatedPTS, sendTime, stream;
          stream = avstreams.get(streamId);
          if (stream == null) {
            // No matching stream
            logger.warn(`warn: No matching stream to id ${streamId}`);
            return;
          }
          if (stream.rtspUploadingClient == null) {
            // No uploading client associated with the stream
            logger.warn(
              `warn: No uploading client associated with the stream ${stream.id}`
            );
            return;
          }
          sendTime = this.getVideoSendTimeForUploadingRTPTimestamp(
            stream,
            rtpTimestamp
          );
          calculatedPTS =
            rtpTimestamp - stream.rtspUploadingClient.videoRTPStartTimestamp;
          return this.emit(
            "video",
            stream,
            nalUnits,
            calculatedPTS,
            calculatedPTS
          );
        }
      );
      this.rtpParser.on(
        "aac_access_units",
        (streamId, accessUnits, rtpTimestamp) => {
          var calculatedPTS, sendTime, stream;
          stream = avstreams.get(streamId);
          if (stream == null) {
            // No matching stream
            logger.warn(`warn: No matching stream to id ${streamId}`);
            return;
          }
          if (stream.rtspUploadingClient == null) {
            // No uploading client associated with the stream
            logger.warn(
              `warn: No uploading client associated with the stream ${stream.id}`
            );
            return;
          }
          sendTime = this.getAudioSendTimeForUploadingRTPTimestamp(
            stream,
            rtpTimestamp
          );
          calculatedPTS = Math.round(
            ((rtpTimestamp -
              stream.rtspUploadingClient.audioRTPStartTimestamp) *
              90000) /
              stream.audioClockRate
          );
          // PTS may not be monotonically increased (it may not be in decoding order)
          return this.emit(
            "audio",
            stream,
            accessUnits,
            calculatedPTS,
            calculatedPTS
          );
        }
      );
    }

    setServerName(name) {
      return (this.serverName = name);
    }

    getNextVideoSequenceNumber(stream) {
      var num;
      num = stream.videoSequenceNumber + 1;
      if (num > 65535) {
        num -= 65535;
      }
      return num;
    }

    getNextAudioSequenceNumber(stream) {
      var num;
      num = stream.audioSequenceNumber + 1;
      if (num > 65535) {
        num -= 65535;
      }
      return num;
    }

    // TODO: Adjust RTP timestamp based on play start time
    getNextVideoRTPTimestamp(stream) {
      if (stream.lastVideoRTPTimestamp != null) {
        return stream.lastVideoRTPTimestamp + stream.videoRTPTimestampInterval;
      } else {
        return 0;
      }
    }

    // TODO: Adjust RTP timestamp based on play start time
    getNextAudioRTPTimestamp(stream) {
      if (stream.lastAudioRTPTimestamp != null) {
        return stream.lastAudioRTPTimestamp + stream.audioRTPTimestampInterval;
      } else {
        return 0;
      }
    }

    getVideoRTPTimestamp(stream, time) {
      return Math.round((time * 90) % TIMESTAMP_ROUNDOFF);
    }

    getAudioRTPTimestamp(stream, time) {
      if (stream.audioClockRate == null) {
        throw new Error("audioClockRate is null");
      }
      return Math.round(
        (time * (stream.audioClockRate / 1000)) % TIMESTAMP_ROUNDOFF
      );
    }

    getVideoSendTimeForUploadingRTPTimestamp(stream, rtpTimestamp) {
      var ref, rtpDiff, timeDiff, videoTimestampInfo;
      videoTimestampInfo =
        (ref = stream.rtspUploadingClient) != null
          ? ref.uploadingTimestampInfo.video
          : void 0;
      if (videoTimestampInfo != null) {
        rtpDiff = rtpTimestamp - videoTimestampInfo.rtpTimestamp; // 90 kHz clock
        timeDiff = rtpDiff / 90;
        return videoTimestampInfo.time + timeDiff;
      } else {
        return Date.now();
      }
    }

    getAudioSendTimeForUploadingRTPTimestamp(stream, rtpTimestamp) {
      var audioTimestampInfo, ref, rtpDiff, timeDiff;
      audioTimestampInfo =
        (ref = stream.rtspUploadingClient) != null
          ? ref.uploadingTimestampInfo.audio
          : void 0;
      if (audioTimestampInfo != null) {
        rtpDiff = rtpTimestamp - audioTimestampInfo.rtpTimestamp;
        timeDiff = (rtpDiff * 1000) / stream.audioClockRate;
        return audioTimestampInfo.time + timeDiff;
      } else {
        return Date.now();
      }
    }

    // @public
    sendVideoData(stream, nalUnits, pts, dts) {
      var i, isLastPacket, isPPSSent, isSPSSent, j, len, nalUnit, nalUnitType;
      isSPSSent = false;
      isPPSSent = false;
      for (i = j = 0, len = nalUnits.length; j < len; i = ++j) {
        nalUnit = nalUnits[i];
        isLastPacket = i === nalUnits.length - 1;
        // detect configuration
        nalUnitType = h264.getNALUnitType(nalUnit);
        if (
          config.dropH264AccessUnitDelimiter &&
          nalUnitType === h264.NAL_UNIT_TYPE_ACCESS_UNIT_DELIMITER
        ) {
          // ignore access unit delimiters
          continue;
        }
        if (nalUnitType === h264.NAL_UNIT_TYPE_SPS) {
          // 7
          isSPSSent = true;
        } else if (nalUnitType === h264.NAL_UNIT_TYPE_PPS) {
          // 8
          isPPSSent = true;
        }
        // If this is keyframe but SPS and PPS do not exist in the
        // same timestamp, we insert them before the keyframe.
        // TODO: Send SPS and PPS as an aggregation packet (STAP-A).
        if (nalUnitType === 5) {
          // keyframe
          // Compensate SPS/PPS if they are not included in nalUnits
          if (!isSPSSent) {
            // nal_unit_type 7
            if (stream.spsNALUnit != null) {
              this.sendNALUnitOverRTSP(
                stream,
                stream.spsNALUnit,
                pts,
                dts,
                false
              );
              // there is a case where timestamps of two keyframes are identical
              // (i.e. nalUnits argument contains multiple keyframes)
              isSPSSent = true;
            } else {
              logger.error("Error: SPS is not set");
            }
          }
          if (!isPPSSent) {
            // nal_unit_type 8
            if (stream.ppsNALUnit != null) {
              this.sendNALUnitOverRTSP(
                stream,
                stream.ppsNALUnit,
                pts,
                dts,
                false
              );
              // there is a case where timestamps of two keyframes are identical
              // (i.e. nalUnits argument contains multiple keyframes)
              isPPSSent = true;
            } else {
              logger.error("Error: PPS is not set");
            }
          }
        }
        this.sendNALUnitOverRTSP(stream, nalUnit, pts, dts, isLastPacket);
      }
    }

    sendNALUnitOverRTSP(stream, nalUnit, pts, dts, marker) {
      if (nalUnit.length > SINGLE_NAL_UNIT_MAX_SIZE) {
        return this.sendVideoPacketWithFragment(stream, nalUnit, pts, marker); // TODO what about dts?
      } else {
        return this.sendVideoPacketAsSingleNALUnit(
          stream,
          nalUnit,
          pts,
          marker
        ); // TODO what about dts?
      }
    }

    // @public
    sendAudioData(stream, accessUnits, pts, dts) {
      var accessUnitLength,
        audioHeader,
        client,
        clientID,
        concatRawDataBlock,
        frameGroups,
        group,
        i,
        j,
        len,
        processedFrames,
        ref,
        rtpBuffer,
        rtpData,
        rtpTimePerFrame,
        timestamp,
        ts;
      if (stream.audioSampleRate == null) {
        throw new Error(
          `audio sample rate has not been detected for stream ${stream.id}`
        );
      }
      // timestamp: RTP timestamp in audioClockRate
      // pts: PTS in 90 kHz clock
      if (stream.audioClockRate !== 90000) {
        // given pts is not in 90 kHz clock
        timestamp = (pts * stream.audioClockRate) / 90000;
      } else {
        timestamp = pts;
      }
      rtpTimePerFrame = 1024;
      if (this.numClients === 0) {
        return;
      }
      if (stream.rtspNumClients === 0) {
        return;
      }
      // No clients connected to the stream
      frameGroups = rtp.groupAudioFrames(accessUnits);
      processedFrames = 0;
      for (i = j = 0, len = frameGroups.length; j < len; i = ++j) {
        group = frameGroups[i];
        concatRawDataBlock = Buffer.concat(group);
        if (++stream.audioSequenceNumber > 65535) {
          stream.audioSequenceNumber -= 65535;
        }
        ts = Math.round(
          (timestamp + rtpTimePerFrame * processedFrames) % TIMESTAMP_ROUNDOFF
        );
        processedFrames += group.length;
        stream.lastAudioRTPTimestamp =
          (timestamp + rtpTimePerFrame * processedFrames) % TIMESTAMP_ROUNDOFF;
        // TODO dts
        rtpData = rtp.createRTPHeader({
          marker: true,
          payloadType: 96,
          sequenceNumber: stream.audioSequenceNumber,
          timestamp: ts,
          ssrc: null
        });
        accessUnitLength = concatRawDataBlock.length;
        // TODO: maximum size of AAC-hbr is 8191 octets
        // TODO: sequence number should start at a random number
        audioHeader = rtp.createAudioHeader({
          accessUnits: group
        });
        rtpData = rtpData.concat(audioHeader);
        ref = stream.rtspClients;
        for (clientID in ref) {
          client = ref[clientID];
          // Append the access unit (rawDataBlock)
          rtpBuffer = Buffer.concat(
            [Buffer.from(rtpData), concatRawDataBlock],
            rtp.RTP_HEADER_LEN + audioHeader.length + accessUnitLength
          );
          if (client.isPlaying) {
            rtp.replaceSSRCInRTP(rtpBuffer, client.audioSSRC);
            client.audioPacketCount++;
            client.audioOctetCount += accessUnitLength;
            logger.tag(
              "rtsp:out",
              `[rtsp:stream:${stream.id}] send audio to ${client.id}: ts=${ts} pts=${pts}`
            );
            if (client.useTCPForAudio) {
              if (client.useHTTP) {
                if (client.httpClientType === "GET") {
                  this.sendDataByTCP(
                    client.socket,
                    client.audioTCPDataChannel,
                    rtpBuffer
                  );
                }
              } else {
                this.sendDataByTCP(
                  client.socket,
                  client.audioTCPDataChannel,
                  rtpBuffer
                );
              }
            } else {
              if (client.clientAudioRTPPort != null) {
                this.audioRTPSocket.send(
                  rtpBuffer,
                  0,
                  rtpBuffer.length,
                  client.clientAudioRTPPort,
                  client.ip,
                  function(err, bytes) {
                    if (err) {
                      return logger.error(
                        `[audioRTPSend] error: ${err.message}`
                      );
                    }
                  }
                );
              }
            }
          }
        }
      }
    }

    sendEOS(stream) {
      var buf, client, clientID, ref, results;
      ref = stream.rtspClients;
      results = [];
      for (clientID in ref) {
        client = ref[clientID];
        logger.debug(
          `[${TAG}:client=${clientID}] sending goodbye for stream ${stream.id}`
        );
        buf = Buffer.from(
          rtp.createGoodbye({
            ssrcs: [client.videoSSRC]
          })
        );
        if (client.useTCPForVideo) {
          if (client.useHTTP) {
            if (client.httpClientType === "GET") {
              this.sendDataByTCP(
                client.socket,
                client.videoTCPControlChannel,
                buf
              );
            }
          } else {
            this.sendDataByTCP(
              client.socket,
              client.videoTCPControlChannel,
              buf
            );
          }
        } else {
          if (client.clientVideoRTCPPort != null) {
            this.videoRTCPSocket.send(
              buf,
              0,
              buf.length,
              client.clientVideoRTCPPort,
              client.ip,
              function(err, bytes) {
                if (err) {
                  return logger.error(`[videoRTCPSend] error: ${err.message}`);
                }
              }
            );
          }
        }
        buf = Buffer.from(
          rtp.createGoodbye({
            ssrcs: [client.audioSSRC]
          })
        );
        if (client.useTCPForAudio) {
          if (client.useHTTP) {
            if (client.httpClientType === "GET") {
              results.push(
                this.sendDataByTCP(
                  client.socket,
                  client.audioTCPControlChannel,
                  buf
                )
              );
            } else {
              results.push(void 0);
            }
          } else {
            results.push(
              this.sendDataByTCP(
                client.socket,
                client.audioTCPControlChannel,
                buf
              )
            );
          }
        } else {
          if (client.clientAudioRTCPPort != null) {
            results.push(
              this.audioRTCPSocket.send(
                buf,
                0,
                buf.length,
                client.clientAudioRTCPPort,
                client.ip,
                function(err, bytes) {
                  if (err) {
                    return logger.error(
                      `[audioRTCPSend] error: ${err.message}`
                    );
                  }
                }
              )
            );
          } else {
            results.push(void 0);
          }
        }
      }
      return results;
    }

    dumpClients() {
      var client, clientID, ref;
      logger.raw(`[rtsp/http: ${Object.keys(this.clients).length} clients]`);
      ref = this.clients;
      for (clientID in ref) {
        client = ref[clientID];
        logger.raw(" " + client.toString());
      }
    }

    setLivePathConsumer(func) {
      return (this.livePathConsumer = func);
    }

    setAuthenticator(func) {
      return (this.authenticator = func);
    }

    start(opts, callback) {
      var ref,
        serverPort,
        udpAudioControlServer,
        udpAudioDataServer,
        udpVideoControlServer,
        udpVideoDataServer;
      serverPort =
        (ref = opts != null ? opts.port : void 0) != null ? ref : this.port;
      this.videoRTPSocket = dgram.createSocket("udp4");
      this.videoRTPSocket.bind(config.videoRTPServerPort);
      this.videoRTCPSocket = dgram.createSocket("udp4");
      this.videoRTCPSocket.bind(config.videoRTCPServerPort);
      this.audioRTPSocket = dgram.createSocket("udp4");
      this.audioRTPSocket.bind(config.audioRTPServerPort);
      this.audioRTCPSocket = dgram.createSocket("udp4");
      this.audioRTCPSocket.bind(config.audioRTCPServerPort);
      this.server = net.createServer(c => {
        var id_str;
        // New client is connected
        this.highestClientID++;
        id_str = "c" + this.highestClientID;
        logger.info(`[${TAG}:client=${id_str}] connected`);
        return generateNewSessionID((err, sessionID) => {
          var client;
          if (err) {
            throw err;
          }
          client = this.clients[id_str] = new RTSPClient({
            id: id_str,
            sessionID: sessionID,
            socket: c,
            ip: c.remoteAddress
          });
          this.numClients++;
          c.setKeepAlive(true, 120000);
          c.clientID = id_str; // TODO: Is this safe?
          c.isAuthenticated = false;
          c.requestCount = 0;
          c.responseCount = 0;
          c.on("close", () => {
            var _client, addr, e, ref1;
            logger.info(`[${TAG}:client=${id_str}] disconnected`);
            logger.debug(
              `[${TAG}:client=${id_str}] teardown: session=${sessionID}`
            );
            try {
              c.end();
            } catch (error) {
              e = error;
              logger.error(`socket.end() error: ${e}`);
            }
            delete this.clients[id_str];
            this.numClients--;
            api.leaveClient(client);
            this.stopSendingRTCP(client);
            ref1 = this.rtspUploadingClients;
            // TODO: Is this fast enough?
            for (addr in ref1) {
              _client = ref1[addr];
              if (_client === client) {
                delete this.rtspUploadingClients[addr];
              }
            }
            return this.dumpClients();
          });
          c.buf = null;
          c.on("error", function(err) {
            logger.error(`Socket error (${c.clientID}): ${err}`);
            return c.destroy();
          });
          return c.on("data", data => {
            return this.handleOnData(c, data);
          });
        });
      });
      this.server.on("error", function(err) {
        return logger.error(`[${TAG}] server error: ${err.message}`);
      });
      udpVideoDataServer = dgram.createSocket("udp4");
      udpVideoDataServer.on("error", function(err) {
        logger.error(`[${TAG}] udp video data receiver error: ${err.message}`);
        throw err;
      });
      udpVideoDataServer.on("message", (msg, rinfo) => {
        var stream;
        stream = this.getStreamByRTSPUDPAddress(
          rinfo.address,
          rinfo.port,
          "video-data"
        );
        if (stream != null) {
          return this.onUploadVideoData(stream, msg, rinfo);
        }
      });
      //      else
      //        logger.warn "[#{TAG}] warn: received UDP video data but no existing client found: #{rinfo.address}:#{rinfo.port}"
      udpVideoDataServer.on("listening", function() {
        var addr;
        addr = udpVideoDataServer.address();
        return logger.debug(
          `[${TAG}] udp video data receiver is listening on port ${addr.port}`
        );
      });
      udpVideoDataServer.bind(config.rtspVideoDataUDPListenPort);
      udpVideoControlServer = dgram.createSocket("udp4");
      udpVideoControlServer.on("error", function(err) {
        logger.error(
          `[${TAG}] udp video control receiver error: ${err.message}`
        );
        throw err;
      });
      udpVideoControlServer.on("message", (msg, rinfo) => {
        var stream;
        stream = this.getStreamByRTSPUDPAddress(
          rinfo.address,
          rinfo.port,
          "video-control"
        );
        if (stream != null) {
          return this.onUploadVideoControl(stream, msg, rinfo);
        }
      });
      //      else
      //        logger.warn "[#{TAG}] warn: received UDP video control data but no existing client found: #{rinfo.address}:#{rinfo.port}"
      udpVideoControlServer.on("listening", function() {
        var addr;
        addr = udpVideoControlServer.address();
        return logger.debug(
          `[${TAG}] udp video control receiver is listening on port ${addr.port}`
        );
      });
      udpVideoControlServer.bind(config.rtspVideoControlUDPListenPort);
      udpAudioDataServer = dgram.createSocket("udp4");
      udpAudioDataServer.on("error", function(err) {
        logger.error(`[${TAG}] udp audio data receiver error: ${err.message}`);
        throw err;
      });
      udpAudioDataServer.on("message", (msg, rinfo) => {
        var stream;
        stream = this.getStreamByRTSPUDPAddress(
          rinfo.address,
          rinfo.port,
          "audio-data"
        );
        if (stream != null) {
          return this.onUploadAudioData(stream, msg, rinfo);
        }
      });
      //      else
      //        logger.warn "[#{TAG}] warn: received UDP audio data but no existing client found: #{rinfo.address}:#{rinfo.port}"
      udpAudioDataServer.on("listening", function() {
        var addr;
        addr = udpAudioDataServer.address();
        return logger.debug(
          `[${TAG}] udp audio data receiver is listening on port ${addr.port}`
        );
      });
      udpAudioDataServer.bind(config.rtspAudioDataUDPListenPort);
      udpAudioControlServer = dgram.createSocket("udp4");
      udpAudioControlServer.on("error", function(err) {
        logger.error(
          `[${TAG}] udp audio control receiver error: ${err.message}`
        );
        throw err;
      });
      udpAudioControlServer.on("message", (msg, rinfo) => {
        var stream;
        stream = this.getStreamByRTSPUDPAddress(
          rinfo.address,
          rinfo.port,
          "audio-control"
        );
        if (stream != null) {
          return this.onUploadAudioControl(stream, msg, rinfo);
        }
      });
      //      else
      //        logger.warn "[#{TAG}] warn: received UDP audio control data but no existing client found: #{rinfo.address}:#{rinfo.port}"
      udpAudioControlServer.on("listening", function() {
        var addr;
        addr = udpAudioControlServer.address();
        return logger.debug(
          `[${TAG}] udp audio control receiver is listening on port ${addr.port}`
        );
      });
      udpAudioControlServer.bind(config.rtspAudioControlUDPListenPort);
      logger.debug(`[${TAG}] starting server on port ${serverPort}`);
      return this.server.listen(serverPort, "0.0.0.0", 511, () => {
        logger.info(`[${TAG}] server started on port ${serverPort}`);
        return typeof callback === "function" ? callback() : void 0;
      });
    }

    stop(callback) {
      var ref;
      return (ref = this.server) != null ? ref.close(callback) : void 0;
    }

    on(event, listener) {
      if (this.eventListeners[event] != null) {
        this.eventListeners[event].push(listener);
      } else {
        this.eventListeners[event] = [listener];
      }
    }

    emit(event, ...args) {
      var j, len, listener, ref;
      if (this.eventListeners[event] != null) {
        ref = this.eventListeners[event];
        for (j = 0, len = ref.length; j < len; j++) {
          listener = ref[j];
          listener(...args);
        }
      }
    }

    // rtsp://localhost:80/live/a -> live/a
    // This method returns null if no stream id is extracted from the uri
    static getStreamIdFromUri(uri, removeDepthFromEnd = 0) {
      var e, pathname, slashPos;
      try {
        pathname = url.parse(uri).pathname;
      } catch (error) {
        e = error;
        return null;
      }
      if (pathname != null && pathname.length > 0) {
        // Remove leading slash
        pathname = pathname.slice(1);
        // Remove trailing slash
        if (pathname[pathname.length - 1] === "/") {
          pathname = pathname.slice(0, +(pathname.length - 2) + 1 || 9e9);
        }
        // Go up directories if removeDepthFromEnd is specified
        while (removeDepthFromEnd > 0) {
          slashPos = pathname.lastIndexOf("/");
          if (slashPos === -1) {
            break;
          }
          pathname = pathname.slice(0, slashPos);
          removeDepthFromEnd--;
        }
      }
      return pathname;
    }

    getStreamByRTSPUDPAddress(addr, port, channelType) {
      var client;
      client = this.rtspUploadingClients[addr + ":" + port];
      if (client != null) {
        return client.uploadingStream;
      }
      return null;
    }

    getStreamByUri(uri) {
      var streamId;
      streamId = RTSPServer.getStreamIdFromUri(uri);
      if (streamId != null) {
        return avstreams.get(streamId);
      } else {
        return null;
      }
    }

    sendVideoSenderReport(stream, client) {
      var buf, rtpTime, time;
      if (stream.timeAtVideoStart == null) {
        return;
      }
      time = new Date().getTime();
      rtpTime = this.getVideoRTPTimestamp(
        stream,
        time - stream.timeAtVideoStart
      );
      if (DEBUG_OUTGOING_RTCP) {
        logger.info(
          `video sender report: rtpTime=${rtpTime} time=${time} timeAtVideoStart=${stream.timeAtVideoStart}`
        );
      }
      buf = Buffer.from(
        rtp.createSenderReport({
          time: time,
          rtpTime: rtpTime,
          ssrc: client.videoSSRC,
          packetCount: client.videoPacketCount,
          octetCount: client.videoOctetCount
        })
      );
      if (client.useTCPForVideo) {
        if (client.useHTTP) {
          if (client.httpClientType === "GET") {
            return this.sendDataByTCP(
              client.socket,
              client.videoTCPControlChannel,
              buf
            );
          }
        } else {
          return this.sendDataByTCP(
            client.socket,
            client.videoTCPControlChannel,
            buf
          );
        }
      } else {
        if (client.clientVideoRTCPPort != null) {
          return this.videoRTCPSocket.send(
            buf,
            0,
            buf.length,
            client.clientVideoRTCPPort,
            client.ip,
            function(err, bytes) {
              if (err) {
                return logger.error(`[videoRTCPSend] error: ${err.message}`);
              }
            }
          );
        }
      }
    }

    sendAudioSenderReport(stream, client) {
      var buf, rtpTime, time;
      if (stream.timeAtAudioStart == null) {
        return;
      }
      time = new Date().getTime();
      rtpTime = this.getAudioRTPTimestamp(
        stream,
        time - stream.timeAtAudioStart
      );
      if (DEBUG_OUTGOING_RTCP) {
        logger.info(
          `audio sender report: rtpTime=${rtpTime} time=${time} timeAtAudioStart=${stream.timeAtAudioStart}`
        );
      }
      buf = Buffer.from(
        rtp.createSenderReport({
          time: time,
          rtpTime: rtpTime,
          ssrc: client.audioSSRC,
          packetCount: client.audioPacketCount,
          octetCount: client.audioOctetCount
        })
      );
      if (client.useTCPForAudio) {
        if (client.useHTTP) {
          if (client.httpClientType === "GET") {
            return this.sendDataByTCP(
              client.socket,
              client.audioTCPControlChannel,
              buf
            );
          }
        } else {
          return this.sendDataByTCP(
            client.socket,
            client.audioTCPControlChannel,
            buf
          );
        }
      } else {
        if (client.clientAudioRTCPPort != null) {
          return this.audioRTCPSocket.send(
            buf,
            0,
            buf.length,
            client.clientAudioRTCPPort,
            client.ip,
            function(err, bytes) {
              if (err) {
                return logger.error(`[audioRTCPSend] error: ${err.message}`);
              }
            }
          );
        }
      }
    }

    stopSendingRTCP(client) {
      if (client.timeoutID != null) {
        clearTimeout(client.timeoutID);
        return (client.timeoutID = null);
      }
    }

    // Send RTCP sender report packets for audio and video streams
    sendSenderReports(stream, client) {
      if (this.clients[client.id] == null) {
        this.stopSendingRTCP(client);
        return;
      }
      if (stream.isAudioStarted) {
        this.sendAudioSenderReport(stream, client);
      }
      if (stream.isVideoStarted) {
        this.sendVideoSenderReport(stream, client);
      }
      return (client.timeoutID = setTimeout(() => {
        return this.sendSenderReports(stream, client);
      }, config.rtcpSenderReportIntervalMs));
    }

    startSendingRTCP(stream, client) {
      this.stopSendingRTCP(client);
      return this.sendSenderReports(stream, client);
    }

    onReceiveVideoRTCP(buf) {}

    // TODO: handle BYE message
    onReceiveAudioRTCP(buf) {}

    // TODO: handle BYE message
    sendDataByTCP(socket, channel, rtpBuffer) {
      var rtpLen, tcpHeader;
      rtpLen = rtpBuffer.length;
      tcpHeader = api.createInterleavedHeader({
        channel: channel,
        payloadLength: rtpLen
      });
      return socket.write(
        Buffer.concat(
          [tcpHeader, rtpBuffer],
          api.INTERLEAVED_HEADER_LEN + rtpBuffer.length
        )
      );
    }

    // Process incoming RTSP data that is tunneled in HTTP POST
    handleTunneledPOSTData(client, data = "", callback) {
      var base64Buf,
        decodedBuf,
        decodedRequest,
        delimiterPos,
        div,
        interleavedData,
        postData,
        processRemainingBuffer,
        remainingPostData,
        req;
      // Concatenate outstanding base64 string
      if (client.postBase64Buf != null) {
        base64Buf = client.postBase64Buf + data;
      } else {
        base64Buf = data;
      }
      if (base64Buf.length > 0) {
        // Length of base64-encoded string is always divisible by 4
        div = base64Buf.length % 4;
        if (div !== 0) {
          // extract last div characters
          client.postBase64Buf = base64Buf.slice(-div);
          base64Buf = base64Buf.slice(0, -div);
        } else {
          client.postBase64Buf = null;
        }
        // Decode base64-encoded data
        decodedBuf = Buffer.from(base64Buf, "base64"); // no base64 input
      } else {
        decodedBuf = Buffer.from([]);
      }
      // Concatenate outstanding buffer
      if (client.postBuf != null) {
        postData = Buffer.concat([client.postBuf, decodedBuf]);
        client.postBuf = null;
      } else {
        postData = decodedBuf;
      }
      if (postData.length === 0) {
        // no data to process
        if (typeof callback === "function") {
          callback(null);
        }
        return;
      }
      // Will be called before return
      processRemainingBuffer = () => {
        if (client.postBase64Buf != null || client.postBuf != null) {
          this.handleTunneledPOSTData(client, "", callback);
        } else {
          if (typeof callback === "function") {
            callback(null);
          }
        }
      };
      // TODO: Do we have to interpret interleaved data here?
      if (config.enableRTSP && postData[0] === api.INTERLEAVED_SIGN) {
        // interleaved data
        interleavedData = api.getInterleavedData(postData);
        if (interleavedData == null) {
          // not enough buffer for an interleaved data
          client.postBuf = postData;
          if (typeof callback === "function") {
            callback(null);
          }
          return;
        }
        // At this point, postData has enough buffer for this interleaved data.
        this.onInterleavedRTPPacketFromClient(client, interleavedData);
        if (postData.length > interleavedData.totalLength) {
          client.postBuf = client.buf.slice(interleavedData.totalLength);
        }
        return processRemainingBuffer();
      } else {
        delimiterPos = Bits.searchBytesInArray(postData, CRLF_CRLF);
        if (delimiterPos === -1) {
          // not found (not enough buffer)
          client.postBuf = postData;
          if (typeof callback === "function") {
            callback(null);
          }
          return;
        }
        decodedRequest = postData.slice(0, delimiterPos).toString("utf8");
        remainingPostData = postData.slice(delimiterPos + CRLF_CRLF.length);
        req = http.parseRequest(decodedRequest);
        if (req == null) {
          // parse error
          logger.error(`Unable to parse request: ${decodedRequest}`);
          if (typeof callback === "function") {
            callback(new Error("malformed request"));
          }
          return;
        }
        if (req.headers["content-length"] != null) {
          req.contentLength = parseInt(req.headers["content-length"]);
          if (remainingPostData.length < req.contentLength) {
            // not enough buffer for the body
            client.postBuf = postData;
            if (typeof callback === "function") {
              callback(null);
            }
            return;
          }
          if (remainingPostData.length > req.contentLength) {
            req.rawbody = remainingPostData.slice(0, req.contentLength);
            client.postBuf = remainingPostData.slice(req.contentLength);
          } else {
            req.rawbody = remainingPostData;
          }
        } else if (remainingPostData.length > 0) {
          client.postBuf = remainingPostData;
        }
        if (DEBUG_HTTP_TUNNEL) {
          logger.info("===request (HTTP tunneled/decoded)===");
          process.stdout.write(decodedRequest);
          logger.info("=============");
        }
        return this.respond(client.socket, req, function(err, output) {
          if (err) {
            logger.error(`[respond] Error: ${err}`);
            if (typeof callback === "function") {
              callback(err);
            }
            return;
          }
          if (output != null) {
            if (DEBUG_HTTP_TUNNEL) {
              logger.info("===response (HTTP tunneled)===");
              process.stdout.write(output);
              logger.info("=============");
            }
            client.getClient.socket.write(output);
          } else {
            if (DEBUG_HTTP_TUNNEL) {
              logger.info("===empty response (HTTP tunneled)===");
            }
          }
          return processRemainingBuffer();
        });
      }
    }

    //  cancelTimeout: (socket) ->
    //    if socket.timeoutTimer?
    //      clearTimeout socket.timeoutTimer

    //  scheduleTimeout: (socket) ->
    //    @cancelTimeout socket
    //    socket.scheduledTimeoutTime = Date.now() + config.keepaliveTimeoutMs
    //    socket.timeoutTimer = setTimeout =>
    //      if not clients[socket.clientID]?
    //        return
    //      if Date.now() < socket.scheduledTimeoutTime
    //        return
    //      logger.info "keepalive timeout: #{socket.clientID}"
    //      @teardownClient socket.clientID
    //    , config.keepaliveTimeoutMs

    // Called when the server received an interleaved RTP packet
    onInterleavedRTPPacketFromClient(client, interleavedData) {
      var senderInfo, stream;
      if (client.uploadingStream != null) {
        stream = client.uploadingStream;
        // TODO: Support multiple streams
        senderInfo = {
          address: null,
          port: null
        };
        switch (interleavedData.channel) {
          case stream.rtspUploadingClient.uploadingChannels.videoData:
            return this.onUploadVideoData(
              stream,
              interleavedData.data,
              senderInfo
            );
          case stream.rtspUploadingClient.uploadingChannels.videoControl:
            return this.onUploadVideoControl(
              stream,
              interleavedData.data,
              senderInfo
            );
          case stream.rtspUploadingClient.uploadingChannels.audioData:
            return this.onUploadAudioData(
              stream,
              interleavedData.data,
              senderInfo
            );
          case stream.rtspUploadingClient.uploadingChannels.audioControl:
            return this.onUploadAudioControl(
              stream,
              interleavedData.data,
              senderInfo
            );
          default:
            return logger.error(
              `Error: unknown interleaved channel: ${interleavedData.channel}`
            );
        }
      }
    }

    // Discard incoming RTP packets if the client is not uploading streams

    // Called when new data comes from TCP connection
    handleOnData(c, data) {
      var buf, bufString, client, id_str, interleavedData, req;
      id_str = c.clientID;
      if (this.clients[id_str] == null) {
        logger.error(`error: invalid client ID: ${id_str}`);
        return;
      }
      client = this.clients[id_str];
      if (client.isSendingPOST) {
        this.handleTunneledPOSTData(client, data.toString("utf8"));
        return;
      }
      if (c.buf != null) {
        c.buf = Buffer.concat([c.buf, data], c.buf.length + data.length);
      } else {
        c.buf = data;
      }
      if (c.buf[0] === api.INTERLEAVED_SIGN) {
        // dollar sign '$' (RFC 2326 - 10.12)
        interleavedData = api.getInterleavedData(c.buf);
        if (interleavedData == null) {
          return;
        }
        // At this point, c.buf has enough buffer for this interleaved data.
        // not enough buffer for an interleaved data
        if (c.buf.length > interleavedData.totalLength) {
          c.buf = c.buf.slice(interleavedData.totalLength);
        } else {
          c.buf = null;
        }
        this.onInterleavedRTPPacketFromClient(client, interleavedData);
        if (c.buf != null) {
          // Process the remaining buffer
          // TODO: Is there more efficient way to do this?
          buf = c.buf;
          c.buf = null;
          this.handleOnData(c, buf);
        }
        return;
      }
      if (c.ongoingRequest != null) {
        req = c.ongoingRequest;
        req.rawbody = Buffer.concat(
          [req.rawbody, data],
          req.rawbody.length + data.length
        );
        if (req.rawbody.length < req.contentLength) {
          return;
        }
        req.socket = c;
        if (req.rawbody.length > req.contentLength) {
          c.buf = req.rawbody.slice(req.contentLength);
          req.rawbody = req.rawbody.slice(0, req.contentLength);
        } else {
          c.buf = null;
        }
        req.body = req.rawbody.toString("utf8");
        if (DEBUG_RTSP) {
          logger.info(`===RTSP/HTTP request (cont) from ${id_str}===`);
          if (DEBUG_RTSP_HEADERS_ONLY) {
            logger.info("(redacted)");
          } else {
            process.stdout.write(data.toString("utf8"));
          }
          logger.info("==================");
        }
      } else {
        bufString = c.buf.toString("utf8");
        if (bufString.indexOf("\r\n\r\n") === -1) {
          return;
        }
        if (DEBUG_RTSP) {
          logger.info(`===RTSP/HTTP request from ${id_str}===`);
          if (DEBUG_RTSP_HEADERS_ONLY) {
            process.stdout.write(bufString.replace(/\r\n\r\n[\s\S]*/, "\n"));
          } else {
            process.stdout.write(bufString);
          }
          logger.info("==================");
        }
        req = http.parseRequest(bufString);
        if (req == null) {
          logger.error(`Unable to parse request: ${bufString}`);
          c.buf = null;
          return;
        }
        req.rawbody = c.buf.slice(req.headerBytes + 4);
        req.socket = c;
        if (req.headers["content-length"] != null) {
          if (req.headers["content-type"] === "application/x-rtsp-tunnelled") {
            // If HTTP tunneling is used, we have to ignore content-length.
            req.contentLength = 0;
          } else {
            req.contentLength = parseInt(req.headers["content-length"]);
          }
          if (req.rawbody.length < req.contentLength) {
            c.ongoingRequest = req;
            return;
          }
          if (req.rawbody.length > req.contentLength) {
            c.buf = req.rawbody.slice(req.contentLength);
            req.rawbody = req.rawbody.slice(0, req.contentLength);
          } else {
            c.buf = null;
          }
        } else {
          if (req.rawbody.length > 0) {
            c.buf = req.rawbody;
          } else {
            c.buf = null;
          }
        }
      }
      c.ongoingRequest = null;
      return this.respond(c, req, (err, output, resultOpts) => {
        var delimPos, headerBytes, i, j, len, out;
        if (err) {
          logger.error(`[respond] Error: ${err}`);
          return;
        }
        if (output != null) {
          // Write the response
          if (DEBUG_RTSP) {
            logger.info(`===RTSP/HTTP response to ${id_str}===`);
          }
          if (output instanceof Array) {
            for (i = j = 0, len = output.length; j < len; i = ++j) {
              out = output[i];
              if (DEBUG_RTSP) {
                logger.info(out);
              }
              c.write(out);
            }
          } else {
            if (DEBUG_RTSP) {
              if (DEBUG_RTSP_HEADERS_ONLY) {
                delimPos = Bits.searchBytesInArray(output, [
                  0x0d,
                  0x0a,
                  0x0d,
                  0x0a
                ]);
                if (delimPos !== -1) {
                  headerBytes = output.slice(0, +(delimPos + 1) + 1 || 9e9);
                } else {
                  headerBytes = output;
                }
                process.stdout.write(headerBytes);
              } else {
                process.stdout.write(output);
              }
            }
            c.write(output);
          }
          if (DEBUG_RTSP) {
            logger.info("===================");
          }
        } else {
          if (DEBUG_RTSP) {
            logger.info(`===RTSP/HTTP empty response to ${id_str}===`);
          }
        }
        if (resultOpts != null ? resultOpts.close : void 0) {
          // Half-close the socket
          c.end();
        }
        if (c.buf != null) {
          // Process the remaining buffer
          buf = c.buf;
          c.buf = null;
          return this.handleOnData(c, buf);
        }
      });
    }

    sendVideoPacketWithFragment(stream, nalUnit, timestamp, marker = true) {
      var client,
        clientID,
        fragmentNumber,
        isKeyFrame,
        nalUnitLen,
        nalUnitType,
        nal_ref_idc,
        ref,
        ref1,
        rtpBuffer,
        rtpData,
        thisNalUnit,
        thisNalUnitLen,
        ts;
      ts = timestamp % TIMESTAMP_ROUNDOFF;
      stream.lastVideoRTPTimestamp = ts;
      if (this.numClients === 0) {
        return;
      }
      if (stream.rtspNumClients === 0) {
        return;
      }
      // No clients connected to the stream
      nalUnitType = nalUnit[0] & 0x1f;
      isKeyFrame = nalUnitType === 5;
      nal_ref_idc = nalUnit[0] & 0b01100000; // skip ">> 5" operation
      nalUnit = nalUnit.slice(1);
      fragmentNumber = 0;
      // We subtract 1 from SINGLE_NAL_UNIT_MAX_SIZE in order to
      // prevent nalUnit from not being fragmented when the length of
      // original nalUnit is equal to SINGLE_NAL_UNIT_MAX_SIZE
      while (nalUnit.length > SINGLE_NAL_UNIT_MAX_SIZE - 1) {
        if (++stream.videoSequenceNumber > 65535) {
          stream.videoSequenceNumber -= 65535;
        }
        fragmentNumber++;
        thisNalUnit = nalUnit.slice(0, SINGLE_NAL_UNIT_MAX_SIZE - 1);
        nalUnit = nalUnit.slice(SINGLE_NAL_UNIT_MAX_SIZE - 1);
        // TODO: sequence number should start at a random number
        rtpData = rtp.createRTPHeader({
          marker: false,
          payloadType: 97,
          sequenceNumber: stream.videoSequenceNumber,
          timestamp: ts,
          ssrc: null
        });
        rtpData = rtpData.concat(
          rtp.createFragmentationUnitHeader({
            nal_ref_idc: nal_ref_idc,
            nal_unit_type: nalUnitType,
            isStart: fragmentNumber === 1,
            isEnd: false
          })
        );
        // Append NAL unit
        thisNalUnitLen = thisNalUnit.length;
        ref = stream.rtspClients;
        for (clientID in ref) {
          client = ref[clientID];
          if (client.isWaitingForKeyFrame && isKeyFrame) {
            client.isPlaying = true;
            client.isWaitingForKeyFrame = false;
          }
          if (client.isPlaying) {
            rtpBuffer = Buffer.concat(
              [Buffer.from(rtpData), thisNalUnit],
              rtp.RTP_HEADER_LEN + 2 + thisNalUnitLen
            );
            rtp.replaceSSRCInRTP(rtpBuffer, client.videoSSRC);
            logger.tag(
              "rtsp:out",
              `[rtsp:stream:${stream.id}] send video to ${client.id}: fragment n=${fragmentNumber} timestamp=${ts} bytes=${rtpBuffer.length} marker=false keyframe=${isKeyFrame}`
            );
            client.videoPacketCount++;
            client.videoOctetCount += thisNalUnitLen;
            if (client.useTCPForVideo) {
              if (client.useHTTP) {
                if (client.httpClientType === "GET") {
                  this.sendDataByTCP(
                    client.socket,
                    client.videoTCPDataChannel,
                    rtpBuffer
                  );
                }
              } else {
                this.sendDataByTCP(
                  client.socket,
                  client.videoTCPDataChannel,
                  rtpBuffer
                );
              }
            } else {
              if (client.clientVideoRTPPort != null) {
                this.videoRTPSocket.send(
                  rtpBuffer,
                  0,
                  rtpBuffer.length,
                  client.clientVideoRTPPort,
                  client.ip,
                  function(err, bytes) {
                    if (err) {
                      return logger.error(
                        `[videoRTPSend] error: ${err.message}`
                      );
                    }
                  }
                );
              }
            }
          }
        }
      }
      // last packet
      if (++stream.videoSequenceNumber > 65535) {
        stream.videoSequenceNumber -= 65535;
      }
      // TODO: sequence number should be started from a random number
      rtpData = rtp.createRTPHeader({
        marker: marker,
        payloadType: 97,
        sequenceNumber: stream.videoSequenceNumber,
        timestamp: ts,
        ssrc: null
      });
      rtpData = rtpData.concat(
        rtp.createFragmentationUnitHeader({
          nal_ref_idc: nal_ref_idc,
          nal_unit_type: nalUnitType,
          isStart: false,
          isEnd: true
        })
      );
      nalUnitLen = nalUnit.length;
      ref1 = stream.rtspClients;
      for (clientID in ref1) {
        client = ref1[clientID];
        if (client.isWaitingForKeyFrame && isKeyFrame) {
          client.isPlaying = true;
          client.isWaitingForKeyFrame = false;
        }
        if (client.isPlaying) {
          rtpBuffer = Buffer.concat(
            [Buffer.from(rtpData), nalUnit],
            rtp.RTP_HEADER_LEN + 2 + nalUnitLen
          );
          rtp.replaceSSRCInRTP(rtpBuffer, client.videoSSRC);
          client.videoPacketCount++;
          client.videoOctetCount += nalUnitLen;
          logger.tag(
            "rtsp:out",
            `[rtsp:stream:${stream.id}] send video to ${
              client.id
            }: fragment-last n=${fragmentNumber + 1} timestamp=${ts} bytes=${
              rtpBuffer.length
            } marker=${marker} keyframe=${isKeyFrame}`
          );
          if (client.useTCPForVideo) {
            if (client.useHTTP) {
              if (client.httpClientType === "GET") {
                this.sendDataByTCP(
                  client.socket,
                  client.videoTCPDataChannel,
                  rtpBuffer
                );
              }
            } else {
              this.sendDataByTCP(
                client.socket,
                client.videoTCPDataChannel,
                rtpBuffer
              );
            }
          } else {
            if (client.clientVideoRTPPort != null) {
              this.videoRTPSocket.send(
                rtpBuffer,
                0,
                rtpBuffer.length,
                client.clientVideoRTPPort,
                client.ip,
                function(err, bytes) {
                  if (err) {
                    return logger.error(`[videoRTPSend] error: ${err.message}`);
                  }
                }
              );
            }
          }
        }
      }
    }

    sendVideoPacketAsSingleNALUnit(stream, nalUnit, timestamp, marker = true) {
      var client,
        clientID,
        isKeyFrame,
        nalUnitLen,
        nalUnitType,
        ref,
        rtpBuffer,
        rtpHeader,
        ts;
      if (++stream.videoSequenceNumber > 65535) {
        stream.videoSequenceNumber -= 65535;
      }
      ts = timestamp % TIMESTAMP_ROUNDOFF;
      stream.lastVideoRTPTimestamp = ts;
      nalUnitType = nalUnit[0] & 0x1f;
      if (this.numClients === 0) {
        return;
      }
      if (stream.rtspNumClients === 0) {
        return;
      }
      // No clients connected to the stream
      isKeyFrame = nalUnitType === 5;
      // TODO: sequence number should be started from a random number
      rtpHeader = rtp.createRTPHeader({
        marker: marker,
        payloadType: 97,
        sequenceNumber: stream.videoSequenceNumber,
        timestamp: ts,
        ssrc: null
      });
      nalUnitLen = nalUnit.length;
      ref = stream.rtspClients;
      for (clientID in ref) {
        client = ref[clientID];
        if (client.isWaitingForKeyFrame && isKeyFrame) {
          client.isPlaying = true;
          client.isWaitingForKeyFrame = false;
        }
        if (client.isPlaying) {
          rtpBuffer = Buffer.concat(
            [Buffer.from(rtpHeader), nalUnit],
            rtp.RTP_HEADER_LEN + nalUnitLen
          );
          rtp.replaceSSRCInRTP(rtpBuffer, client.videoSSRC);
          client.videoPacketCount++;
          client.videoOctetCount += nalUnitLen;
          logger.tag(
            "rtsp:out",
            `[rtsp:stream:${stream.id}] send video to ${client.id}: single timestamp=${timestamp} keyframe=${isKeyFrame}`
          );
          if (client.useTCPForVideo) {
            if (client.useHTTP) {
              if (client.httpClientType === "GET") {
                this.sendDataByTCP(
                  client.socket,
                  client.videoTCPDataChannel,
                  rtpBuffer
                );
              }
            } else {
              this.sendDataByTCP(
                client.socket,
                client.videoTCPDataChannel,
                rtpBuffer
              );
            }
          } else {
            if (client.clientVideoRTPPort != null) {
              this.videoRTPSocket.send(
                rtpBuffer,
                0,
                rtpBuffer.length,
                client.clientVideoRTPPort,
                client.ip,
                function(err, bytes) {
                  if (err) {
                    return logger.error(`[videoRTPSend] error: ${err.message}`);
                  }
                }
              );
            }
          }
        }
      }
    }

    static getISO8601DateString() {
      var d, str;
      d = new Date();
      str =
        `${d.getUTCFullYear()}-${pad(2, d.getUTCMonth() + 1)}-${pad(
          2,
          d.getUTCDate()
        )}T` +
        `${pad(2, d.getUTCHours())}:${pad(2, d.getUTCMinutes())}:${pad(
          2,
          d.getUTCSeconds()
        )}.` +
        `${pad(4, d.getUTCMilliseconds())}Z`;
      return str;
    }

    // @return callback(err, isAuthenticated)
    authenticate(req, callback) {
      var decodedToken, match, password, token, username;
      if (this.authenticator == null) {
        return callback(null, true);
      }
      if ((match = /^Basic (\S+)/.exec(req.headers.authorization)) != null) {
        token = match[1];
        decodedToken = Buffer.from(token, "base64").toString("utf8");
        if ((match = /^(.*?):(.*)/.exec(decodedToken)) != null) {
          username = match[1];
          password = match[2];
          return this.authenticator(username, password, callback);
        }
      }
      return callback(null, false);
    }

    consumePathname(uri, callback) {
      var authSuccess, pathname;
      if (this.livePathConsumer != null) {
        return this.livePathConsumer(uri, callback);
      } else {
        pathname = url.parse(uri).pathname.slice(1);
        // TODO: Implement authentication yourself
        authSuccess = true;
        if (authSuccess) {
          return callback(null);
        } else {
          return callback(new Error("Invalid access"));
        }
      }
    }

    respondWithUnsupportedTransport(callback, headers) {
      var name, res, value;
      res = "RTSP/1.0 461 Unsupported Transport\n";
      if (headers != null) {
        for (name in headers) {
          value = headers[name];
          res += `${name}: ${value}\n`;
        }
      }
      res += "\n";
      return callback(null, res.replace(/\n/g, "\r\n"));
    }

    notFound(protocol, opts, callback) {
      var res;
      res = `${protocol}/1.0 404 Not Found
Content-Length: 9
Content-Type: text/plain
`;
      if (opts != null ? opts.keepalive : void 0) {
        res += "Connection: keep-alive\n";
      } else {
        res += "Connection: close\n";
      }
      res += `
Not Found`;
      return callback(null, res.replace(/\n/g, "\r\n"));
    }

    respondWithServerError(req, protocol, callback) {
      var ref, res;
      if (protocol == null) {
        protocol = "RTSP";
      }
      res = `${protocol}/1.0 500 Internal Server Error
Date: ${api.getDateHeader()}
Content-Length: 21
Content-Type: text/plain

Internal Server Error`.replace(/\n/g, "\r\n");
      return callback(null, res, {
        close:
          protocol === "HTTP" &&
          ((ref = req.headers.connection) != null
            ? ref.toLowerCase()
            : void 0) !== "keep-alive"
      });
    }

    respondWithNotFound(req, protocol, callback) {
      var ref, res;
      if (protocol == null) {
        protocol = "RTSP";
      }
      res = `${protocol}/1.0 404 Not Found
Date: ${api.getDateHeader()}
Content-Length: 9
Content-Type: text/plain

Not Found`.replace(/\n/g, "\r\n");
      return callback(null, res, {
        close:
          protocol === "HTTP" &&
          ((ref = req.headers.connection) != null
            ? ref.toLowerCase()
            : void 0) !== "keep-alive"
      });
    }

    respondWithUnauthorized(req, protocol, callback) {
      var ref, res;
      if (protocol == null) {
        protocol = "RTSP";
      }
      res = `${protocol}/1.0 401 Unauthorized
Date: ${api.getDateHeader()}
Content-Length: 12
Content-Type: text/plain
WWW-Authenticate: Basic realm="Restricted"

Unauthorized`.replace(/\n/g, "\r\n");
      return callback(null, res, {
        close:
          protocol === "HTTP" &&
          ((ref = req.headers.connection) != null
            ? ref.toLowerCase()
            : void 0) !== "keep-alive"
      });
    }

    respondOptions(socket, req, callback) {
      var ref, res;
      res = `RTSP/1.0 200 OK
CSeq: ${(ref = req.headers.cseq) != null ? ref : 0}
Public: DESCRIBE, SETUP, TEARDOWN, PLAY, PAUSE, ANNOUNCE, RECORD

`.replace(/\n/g, "\r\n");
      return callback(null, res);
    }

    respondPost(socket, req, callback) {
      var client, getClient, pathname;
      client = this.clients[socket.clientID];
      pathname = url.parse(req.uri).pathname;
      if (
        config.enableRTMPT &&
        /^\/(?:fcs|open|idle|send|close)\//.test(pathname)
      ) {
        if (client.clientType == null) {
          client.clientType = "rtmpt";
          this.dumpClients();
        }
        if (this.rtmptCallback != null) {
          this.rtmptCallback(req, (err, output) => {
            if (err) {
              logger.error(`[rtmpt] Error: ${err}`);
              return this.respondWithNotFound(req, "HTTP", callback);
            } else {
              return callback(err, output);
            }
          });
        } else {
          this.respondWithNotFound(req, "HTTP", callback);
        }
      } else if (config.enableRTSP) {
        // TODO: POST/GET connections may be re-initialized
        // Incoming channel
        if (this.httpSessions[req.headers["x-sessioncookie"]] == null) {
          if (this.httpHandler != null) {
            this.respondWithNotFound(req, "HTTP", callback);
          } else {
            // Request cannot be handled; close the connection
            callback(null, null, {
              close: true
            });
          }
          return;
        }
        socket.isAuthenticated = true;
        client.sessionCookie = req.headers["x-sessioncookie"];
        this.httpSessions[client.sessionCookie].post = client;
        getClient = this.httpSessions[client.sessionCookie].get;
        // Make circular reference
        getClient.postClient = client;
        client.getClient = getClient;
        client.useHTTP = true;
        client.httpClientType = "POST";
        client.isSendingPOST = true;
        if (req.body != null) {
          this.handleTunneledPOSTData(client, req.body);
        }
        // There's no response from the server
      } else if (this.httpHandler != null) {
        this.httpHandler.handlePath(pathname, req, function(err, output) {
          var ref;
          return callback(err, output, {
            close:
              ((ref = req.headers.connection) != null
                ? ref.toLowerCase()
                : void 0) !== "keep-alive"
          });
        });
      } else {
        // Request cannot be handled; close the connection
        callback(null, null, {
          close: true
        });
      }
    }

    respondGet(socket, req, callback) {
      var client, liveRegex, match, pathname, recordedRegex;
      liveRegex = new RegExp(`^/${config.liveApplicationName}/(.*)$`);
      recordedRegex = new RegExp(`^/${config.recordedApplicationName}/(.*)$`);
      client = this.clients[socket.clientID];
      pathname = url.parse(req.uri).pathname;
      if (config.enableRTSP && (match = liveRegex.exec(req.uri)) != null) {
        // Outgoing channel
        this.consumePathname(req.uri, err => {
          if (err) {
            logger.warn(`Failed to consume pathname: ${err}`);
            this.respondWithNotFound(req, "HTTP", callback);
            return;
          }
          return this.authenticate(req, (err, ok) => {
            var postClient, res;
            if (err) {
              logger.error(
                `[${TAG}:client=${socket.clientID}] authenticate() error: ${err.message}`
              );
              this.respondWithServerError(req, req.protocolName, callback);
              return;
            }
            if (!ok) {
              logger.debug(
                `[${TAG}:client=${socket.clientID}] authentication failed`
              );
              this.respondWithUnauthorized(req, req.protocolName, callback);
              return;
            }
            client.sessionCookie = req.headers["x-sessioncookie"];
            client.useHTTP = true;
            client.httpClientType = "GET";
            if (this.httpSessions[client.sessionCookie] != null) {
              postClient = this.httpSessions[client.sessionCookie].post;
              if (postClient != null) {
                postClient.getClient = client;
                client.postClient = postClient;
              }
            } else {
              this.httpSessions[client.sessionCookie] = {};
            }
            this.httpSessions[client.sessionCookie].get = client;
            socket.isAuthenticated = true;
            res = `HTTP/1.0 200 OK
Server: ${this.serverName}
Connection: close
Date: ${api.getDateHeader()}
Cache-Control: no-store
Pragma: no-cache
Content-Type: application/x-rtsp-tunnelled

`.replace(/\n/g, "\r\n");
            // Do not close the connection
            return callback(null, res);
          });
        });
      } else if (
        config.enableRTSP &&
        (match = recordedRegex.exec(req.uri)) != null
      ) {
        // Outgoing channel
        this.consumePathname(req.uri, err => {
          if (err) {
            logger.warn(`Failed to consume pathname: ${err}`);
            this.respondWithNotFound(req, "HTTP", callback);
            return;
          }
          return this.authenticate(req, (err, ok) => {
            var postClient, res;
            if (err) {
              logger.error(
                `[${TAG}:client=${socket.clientID}] authenticate() error: ${err.message}`
              );
              this.respondWithServerError(req, req.protocolName, callback);
              return;
            }
            if (!ok) {
              logger.debug(
                `[${TAG}:client=${socket.clientID}] authentication failed`
              );
              this.respondWithUnauthorized(req, req.protocolName, callback);
              return;
            }
            client.sessionCookie = req.headers["x-sessioncookie"];
            client.useHTTP = true;
            client.httpClientType = "GET";
            if (this.httpSessions[client.sessionCookie] != null) {
              postClient = this.httpSessions[client.sessionCookie].post;
              if (postClient != null) {
                postClient.getClient = client;
                client.postClient = postClient;
              }
            } else {
              this.httpSessions[client.sessionCookie] = {};
            }
            this.httpSessions[client.sessionCookie].get = client;
            socket.isAuthenticated = true;
            res = `HTTP/1.0 200 OK
Server: ${this.serverName}
Connection: close
Date: ${api.getDateHeader()}
Cache-Control: no-store
Pragma: no-cache
Content-Type: application/x-rtsp-tunnelled

`.replace(/\n/g, "\r\n");
            // Do not close the connection
            return callback(null, res);
          });
        });
      } else if (this.httpHandler != null) {
        this.httpHandler.handlePath(pathname, req, function(err, output) {
          var ref;
          return callback(err, output, {
            close:
              ((ref = req.headers.connection) != null
                ? ref.toLowerCase()
                : void 0) !== "keep-alive"
          });
        });
      } else {
        // Request cannot be handled; close the connection
        callback(null, null, {
          close: true
        });
      }
    }

    respondDescribe(socket, req, callback) {
      var client;
      client = this.clients[socket.clientID];
      return this.consumePathname(req.uri, err => {
        if (err) {
          this.respondWithNotFound(req, "RTSP", callback);
          return;
        }
        return this.authenticate(req, (err, ok) => {
          var ascInfo, body, dateHeader, e, res, sdpData, stream, streamId;
          if (err) {
            logger.error(
              `[${TAG}:client=${socket.clientID}] authenticate() error: ${err.message}`
            );
            this.respondWithServerError(req, req.protocolName, callback);
            return;
          }
          if (!ok) {
            logger.debug(
              `[${TAG}:client=${socket.clientID}] authentication failed`
            );
            this.respondWithUnauthorized(req, req.protocolName, callback);
            return;
          }
          socket.isAuthenticated = true;
          client.bandwidth = req.headers.bandwidth;
          streamId = RTSPServer.getStreamIdFromUri(req.uri);
          stream = null;
          if (streamId != null) {
            stream = avstreams.get(streamId);
          }
          client.stream = stream;
          if (stream == null) {
            logger.info(
              `[${TAG}:client=${client.id}] requested stream not found: ${streamId}`
            );
            this.respondWithNotFound(req, "RTSP", callback);
            return;
          }
          sdpData = {
            username: "-",
            sessionID: client.sessionID,
            sessionVersion: client.sessionID,
            addressType: "IP4",
            unicastAddress: api.getMeaningfulIPTo(socket)
          };
          if (stream.isAudioStarted) {
            sdpData.hasAudio = true;
            sdpData.audioPayloadType = 96;
            sdpData.audioEncodingName = "mpeg4-generic";
            sdpData.audioClockRate = stream.audioClockRate;
            sdpData.audioChannels = stream.audioChannels;
            sdpData.audioSampleRate = stream.audioSampleRate;
            sdpData.audioObjectType = stream.audioObjectType;
            ascInfo = stream.audioASCInfo;
            // Check whether explicit hierarchical signaling of SBR is used
            if (
              (ascInfo != null ? ascInfo.explicitHierarchicalSBR : void 0) &&
              config.rtspDisableHierarchicalSBR
            ) {
              logger.debug(
                `[${TAG}:client=${client.id}] converting hierarchical signaling of SBR` +
                  ` (AudioSpecificConfig=0x${stream.audioSpecificConfig.toString(
                    "hex"
                  )})` +
                  " to backward compatible signaling"
              );
              sdpData.audioSpecificConfig = Buffer.from(
                aac.createAudioSpecificConfig(ascInfo)
              );
            } else if (stream.audioSpecificConfig != null) {
              sdpData.audioSpecificConfig = stream.audioSpecificConfig;
            } else {
              // no AudioSpecificConfig available
              sdpData.audioSpecificConfig = Buffer.from(
                aac.createAudioSpecificConfig({
                  audioObjectType: stream.audioObjectType,
                  samplingFrequency: stream.audioSampleRate,
                  channels: stream.audioChannels,
                  frameLength: 1024 // TODO: How to detect 960?
                })
              );
            }
            logger.debug(
              `[${TAG}:client=${
                client.id
              }] sending AudioSpecificConfig: 0x${sdpData.audioSpecificConfig.toString(
                "hex"
              )}`
            );
          }
          if (stream.isVideoStarted) {
            sdpData.hasVideo = true;
            sdpData.videoPayloadType = 97;
            sdpData.videoEncodingName = "H264"; // must be H264
            sdpData.videoClockRate = 90000; // must be 90000
            sdpData.videoProfileLevelId = stream.videoProfileLevelId;
            if (stream.spropParameterSets !== "") {
              sdpData.videoSpropParameterSets = stream.spropParameterSets;
            }
            sdpData.videoHeight = stream.videoHeight;
            sdpData.videoWidth = stream.videoWidth;
            sdpData.videoFrameRate = stream.videoFrameRate.toFixed(1);
          }
          if (stream.isRecorded()) {
            sdpData.durationSeconds = stream.durationSeconds;
          }
          try {
            body = sdp.createSDP(sdpData);
          } catch (error) {
            e = error;
            logger.error(`error: Unable to create SDP: ${e}`);
            callback(new Error("Unable to create SDP"));
            return;
          }
          if (/^HTTP\//.test(req.protocol)) {
            res = "HTTP/1.0 200 OK\n";
          } else {
            res = "RTSP/1.0 200 OK\n";
          }
          if (req.headers.cseq != null) {
            res += `CSeq: ${req.headers.cseq}\n`;
          }
          dateHeader = api.getDateHeader();
          res += `Content-Base: ${req.uri}/
Content-Length: ${body.length}
Content-Type: application/sdp
Date: ${dateHeader}
Expires: ${dateHeader}
Session: ${client.sessionID};timeout=60
Server: ${this.serverName}
Cache-Control: no-cache

`;
          return callback(null, res.replace(/\n/g, "\r\n") + body);
        });
      });
    }

    respondSetup(socket, req, callback) {
      var ch1,
        ch2,
        client,
        controlPort,
        control_ch,
        dataPort,
        data_ch,
        dateHeader,
        j,
        len,
        match,
        media,
        mediaType,
        ref,
        ref1,
        res,
        sdpInfo,
        serverPort,
        setupStreamId,
        ssrc,
        stream,
        streamId,
        target,
        track,
        transportHeader,
        useTCPTransport;
      client = this.clients[socket.clientID];
      if (!socket.isAuthenticated) {
        this.respondWithNotFound(req, "RTSP", callback);
        return;
      }
      serverPort = null;
      track = null;
      if (
        DEBUG_DISABLE_UDP_TRANSPORT &&
        !/\bTCP\b/.test(req.headers.transport)
      ) {
        // Disable UDP transport and force the client to switch to TCP transport
        logger.info("Unsupported transport: UDP is disabled");
        this.respondWithUnsupportedTransport(callback, {
          CSeq: req.headers.cseq
        });
        return;
      }
      client.mode = "PLAY";
      if ((match = /;mode=([^;]*)/.exec(req.headers.transport)) != null) {
        client.mode = match[1].toUpperCase(); // PLAY or RECORD
      }
      if (client.mode === "RECORD") {
        sdpInfo = client.announceSDPInfo;
        if ((match = /\/([^\/]+)$/.exec(req.uri)) != null) {
          setupStreamId = match[1];
          mediaType = null;
          ref = sdpInfo.media;
          for (j = 0, len = ref.length; j < len; j++) {
            media = ref[j];
            if (
              ((ref1 = media.attributes) != null ? ref1.control : void 0) ===
              setupStreamId
            ) {
              mediaType = media.media;
              break;
            }
          }
          if (mediaType == null) {
            throw new Error(`streamid not found: ${setupStreamId}`);
          }
        } else {
          throw new Error(`Unknown URI: ${req.uri}`);
        }
        streamId = RTSPServer.getStreamIdFromUri(req.uri, 1);
        stream = avstreams.get(streamId);
        if (stream == null) {
          logger.warn(
            `warning: SETUP specified non-existent stream: ${streamId}`
          );
          logger.warn("         Stream has to be created by ANNOUNCE method.");
          stream = avstreams.create(streamId);
          stream.type = avstreams.STREAM_TYPE_LIVE;
        }
        if (stream.rtspUploadingClient == null) {
          stream.rtspUploadingClient = {};
        }
        if (stream.rtspUploadingClient.uploadingChannels == null) {
          stream.rtspUploadingClient.uploadingChannels = {};
        }
        if (
          (match = /;interleaved=(\d)-(\d)/.exec(req.headers.transport)) != null
        ) {
          if (client.clientType == null) {
            client.clientType = "publish-tcp";
            this.dumpClients();
          }
          if (mediaType === "video") {
            stream.rtspUploadingClient.uploadingChannels.videoData = parseInt(
              match[1]
            );
            stream.rtspUploadingClient.uploadingChannels.videoControl = parseInt(
              match[2]
            );
          } else {
            stream.rtspUploadingClient.uploadingChannels.audioData = parseInt(
              match[1]
            );
            stream.rtspUploadingClient.uploadingChannels.audioControl = parseInt(
              match[2]
            );
          }
          // interleaved mode (use current connection)
          transportHeader = req.headers.transport.replace(/mode=[^;]*/, "");
        } else {
          if (client.clientType == null) {
            client.clientType = "publish-udp";
            this.dumpClients();
          }
          if (mediaType === "video") {
            [dataPort, controlPort] = [
              config.rtspVideoDataUDPListenPort,
              config.rtspVideoControlUDPListenPort
            ];
            if (
              (match = /;client_port=(\d+)-(\d+)/.exec(
                req.headers.transport
              )) != null
            ) {
              logger.debug(
                `registering video rtspUploadingClient ${client.ip}:${parseInt(
                  match[1]
                )}`
              );
              logger.debug(
                `registering video rtspUploadingClient ${client.ip}:${parseInt(
                  match[2]
                )}`
              );
              this.rtspUploadingClients[
                client.ip + ":" + parseInt(match[1])
              ] = client;
              this.rtspUploadingClients[
                client.ip + ":" + parseInt(match[2])
              ] = client; // audio
            }
          } else {
            [dataPort, controlPort] = [
              config.rtspAudioDataUDPListenPort,
              config.rtspAudioControlUDPListenPort
            ];
            if (
              (match = /;client_port=(\d+)-(\d+)/.exec(
                req.headers.transport
              )) != null
            ) {
              logger.debug(
                `registering audio rtspUploadingClient ${client.ip}:${parseInt(
                  match[1]
                )}`
              );
              logger.debug(
                `registering audio rtspUploadingClient ${client.ip}:${parseInt(
                  match[2]
                )}`
              );
              this.rtspUploadingClients[
                client.ip + ":" + parseInt(match[1])
              ] = client;
              this.rtspUploadingClients[
                client.ip + ":" + parseInt(match[2])
              ] = client;
            }
          }
          // client will send packets to "source" address which is specified here
          //                          "source=#{api.getMeaningfulIPTo socket};" +
          transportHeader =
            req.headers.transport.replace(/mode=[^;]*/, "") +
            `server_port=${dataPort}-${controlPort}`;
        }
        dateHeader = api.getDateHeader();
        res = `RTSP/1.0 200 OK
Date: ${dateHeader}
Expires: ${dateHeader}
Transport: ${transportHeader}
Session: ${client.sessionID};timeout=60
CSeq: ${req.headers.cseq}
Server: ${this.serverName}
Cache-Control: no-cache

`.replace(/\n/g, "\r\n");
        return callback(null, res); // PLAY mode
      } else {
        if (/trackID=1\/?$/.test(req.uri)) {
          // audio
          track = "audio";
          if (client.useHTTP) {
            ssrc = client.getClient.audioSSRC;
          } else {
            ssrc = client.audioSSRC;
          }
          serverPort = `${config.audioRTPServerPort}-${config.audioRTCPServerPort}`;
          if (
            (match = /;client_port=(\d+)-(\d+)/.exec(req.headers.transport)) !=
            null
          ) {
            client.clientAudioRTPPort = parseInt(match[1]);
            client.clientAudioRTCPPort = parseInt(match[2]);
          }
        } else {
          track = "video";
          if (client.useHTTP) {
            ssrc = client.getClient.videoSSRC;
          } else {
            ssrc = client.videoSSRC;
          }
          serverPort = `${config.videoRTPServerPort}-${config.videoRTCPServerPort}`;
          if (
            (match = /;client_port=(\d+)-(\d+)/.exec(req.headers.transport)) !=
            null
          ) {
            client.clientVideoRTPPort = parseInt(match[1]);
            client.clientVideoRTCPPort = parseInt(match[2]);
          }
        }
        if (/\bTCP\b/.test(req.headers.transport)) {
          useTCPTransport = true;
          if (
            (match = /;interleaved=(\d+)-(\d+)/.exec(req.headers.transport)) !=
            null
          ) {
            ch1 = parseInt(match[1]);
            ch2 = parseInt(match[2]);
            // even channel number is used for data, odd number is for control
            if (ch1 % 2 === 0) {
              [data_ch, control_ch] = [ch1, ch2];
            } else {
              [data_ch, control_ch] = [ch2, ch1];
            }
          } else {
            if (track === "audio") {
              data_ch = 0;
              control_ch = 1;
            } else {
              data_ch = 2;
              control_ch = 3;
            }
          }
          if (track === "video") {
            if (client.useHTTP) {
              target = client.getClient;
            } else {
              target = client;
            }
            target.videoTCPDataChannel = data_ch;
            target.videoTCPControlChannel = control_ch;
            target.useTCPForVideo = true;
          } else {
            if (client.useHTTP) {
              target = client.getClient;
            } else {
              target = client;
            }
            target.audioTCPDataChannel = data_ch;
            target.audioTCPControlChannel = control_ch;
            target.useTCPForAudio = true;
          }
        } else {
          useTCPTransport = false;
          if (track === "video") {
            client.useTCPForVideo = false;
          } else {
            client.useTCPForAudio = false;
          }
        }
        client.supportsReliableRTP =
          req.headers["x-retransmit"] === "our-retransmit";
        if (req.headers["x-dynamic-rate"] != null) {
          client.supportsDynamicRate = req.headers["x-dynamic-rate"] === "1";
        } else {
          client.supportsDynamicRate = client.supportsReliableRTP;
        }
        if (req.headers["x-transport-options"] != null) {
          match = /late-tolerance=([0-9.]+)/.exec(
            req.headers["x-transport-options"]
          );
          if (match != null) {
            client.lateTolerance = parseFloat(match[1]);
          }
        }
        if (useTCPTransport) {
          if (/;interleaved=/.test(req.headers.transport)) {
            transportHeader = req.headers.transport; // Maybe HTTP tunnelling
          } else {
            transportHeader =
              req.headers.transport +
              `;interleaved=${data_ch}-${control_ch}` +
              `;ssrc=${zeropad(8, ssrc.toString(16))}`;
          }
        } else {
          //                          ";source=#{api.getMeaningfulIPTo socket}" +
          transportHeader =
            req.headers.transport +
            `;server_port=${serverPort};ssrc=${zeropad(8, ssrc.toString(16))}`;
        }
        dateHeader = api.getDateHeader();
        res = `RTSP/1.0 200 OK
Date: ${dateHeader}
Expires: ${dateHeader}
Transport: ${transportHeader}
Session: ${client.sessionID};timeout=60
CSeq: ${req.headers.cseq}
Server: ${this.serverName}
Cache-Control: no-cache

`.replace(/\n/g, "\r\n");
        return callback(null, res);
      }
    }

    // after the response, client will send one or two RTP packets to this server
    respondPlay(socket, req, callback) {
      var client,
        doResumeLater,
        match,
        preventFromPlaying,
        rangeStartTime,
        seq,
        startTime,
        stream;
      if (
        req.headers.range != null &&
        (match = /npt=([\d.]+)-/.exec(req.headers.range)) != null
      ) {
        startTime = parseFloat(match[1]);
      } else {
        startTime = null;
      }
      client = this.clients[socket.clientID];
      if (!socket.isAuthenticated) {
        this.respondWithNotFound(req, "RTSP", callback);
        return;
      }
      preventFromPlaying = false;
      stream = client.stream;
      if (stream == null) {
        this.respondWithNotFound(req, "RTSP", callback);
        return;
      }
      doResumeLater = false;
      rangeStartTime = 0;
      seq = new Sequent();
      if (stream.isRecorded()) {
        if (startTime == null && stream.isPaused()) {
          startTime = stream.getCurrentPlayTime();
          logger.info(
            `[${TAG}:client=${
              client.id
            }] resuming stream at ${stream.getCurrentPlayTime()}`
          );
        }
        if (startTime != null) {
          logger.info(`[${TAG}:client=${client.id}] seek to ${startTime}`);
          stream.pause();
          rangeStartTime = startTime;
          stream.seek(startTime, function(err, actualStartTime) {
            if (err) {
              logger.error(
                `[${TAG}:client=${client.id}] error: seek failed: ${err}`
              );
              return;
            }
            logger.debug(
              `[${TAG}:client=${client.id}] finished seeking stream to ${startTime}`
            );
            return stream.sendVideoPacketsSinceLastKeyFrame(
              startTime,
              function() {
                doResumeLater = true;
                return seq.done();
              }
            );
          });
        } else {
          seq.done();
        }
      } else {
        seq.done();
      }
      //    if (req.headers['user-agent']?.indexOf('QuickTime') > -1) and
      //    not client.getClient?.useTCPForVideo
      //      # QuickTime produces poor quality image over UDP.
      //      # So we let QuickTime switch transport.
      //      logger.info "UDP is disabled for QuickTime"
      //      preventFromPlaying = true

      //    Range: clock=#{RTSPServer.getISO8601DateString()}-
      // RTP-Info is defined in Section 12.33 in RFC 2326
      // seq: Indicates the sequence number of the first packet of the stream.
      // rtptime: Indicates the RTP timestamp corresponding to the time value in
      //          the Range response header.
      // TODO: Send this response after the first packet for this stream arrives
      return seq.wait(1, () => {
        var baseUrl, res, rtpInfos;
        baseUrl = req.uri.replace(/\/$/, "");
        rtpInfos = [];
        if (stream.isAudioStarted) {
          rtpInfos.push(
            `url=${baseUrl}/trackID=1;seq=${this.getNextAudioSequenceNumber(
              stream
            )};rtptime=${this.getNextAudioRTPTimestamp(stream)}`
          );
        }
        if (stream.isVideoStarted) {
          rtpInfos.push(
            `url=${baseUrl}/trackID=2;seq=${this.getNextVideoSequenceNumber(
              stream
            )};rtptime=${this.getNextVideoRTPTimestamp(stream)}`
          );
        }
        res = `RTSP/1.0 200 OK
Range: npt=${rangeStartTime}-
Session: ${client.sessionID};timeout=60
CSeq: ${req.headers.cseq}
RTP-Info: ${rtpInfos.join(",")}
Server: ${this.serverName}
Cache-Control: no-cache

`.replace(/\n/g, "\r\n");
        if (!preventFromPlaying) {
          stream.rtspNumClients++;
          client.enablePlaying();
          if (client.useHTTP) {
            logger.info(
              `[${TAG}:client=${client.getClient.id}] start streaming over HTTP GET`
            );
            stream.rtspClients[client.getClient.id] = client.getClient;
            client.clientType = "http-post";
            client.getClient.clientType = "http-get";
            this.dumpClients();
          } else if (client.useTCPForVideo) {
            // or client.useTCPForAudio?
            logger.info(
              `[${TAG}:client=${client.id}] start streaming over TCP`
            );
            stream.rtspClients[client.id] = client;
            client.clientType = "tcp";
            this.dumpClients();
          } else {
            logger.debug(
              `[${TAG}:client=${client.id}] start streaming over UDP`
            );
            if (ENABLE_START_PLAYING_FROM_KEYFRAME && stream.isVideoStarted) {
              client.isWaitingForKeyFrame = true;
            } else {
              client.isPlaying = true;
            }
            stream.rtspClients[client.id] = client;
            client.clientType = "udp";
            this.dumpClients();
          }
          if (client.useHTTP) {
            this.startSendingRTCP(stream, client.getClient);
          } else {
            this.startSendingRTCP(stream, client);
          }
        } else {
          logger.info(`[${TAG}:client=${client.id}] not playing`);
        }
        callback(null, res);
        if (doResumeLater) {
          return stream.resume(false);
        }
      });
    }

    respondPause(socket, req, callback) {
      var client, res;
      client = this.clients[socket.clientID];
      if (!socket.isAuthenticated) {
        this.respondWithNotFound(req, "RTSP", callback);
        return;
      }
      this.stopSendingRTCP(client);
      client.disablePlaying();
      if (client.stream.isRecorded()) {
        client.stream.pause();
      }
      res = `RTSP/1.0 200 OK
Session: ${client.sessionID};timeout=60
CSeq: ${req.headers.cseq}
Cache-Control: no-cache

`.replace(/\n/g, "\r\n");
      return callback(null, res);
    }

    respondTeardown(socket, req, callback) {
      var client, ref, res, stream;
      client = this.clients[socket.clientID];
      stream = (ref = client.uploadingStream) != null ? ref : client.stream;
      if (client === (stream != null ? stream.rtspUploadingClient : void 0)) {
        logger.info(
          `[${TAG}:client=${client.id}] finished uploading stream ${stream.id}`
        );
        stream.rtspUploadingClient = null;
        stream.emit("end");
      }
      if (
        (stream != null ? stream.type : void 0) ===
        avstreams.STREAM_TYPE_RECORDED
      ) {
        if (typeof stream.teardown === "function") {
          stream.teardown();
        }
      }
      if (!socket.isAuthenticated) {
        this.respondWithNotFound(req, "RTSP", callback);
        return;
      }
      client.disablePlaying();
      if ((stream != null ? stream.rtspClients[client.id] : void 0) != null) {
        delete stream.rtspClients[client.id];
        stream.rtspNumClients--;
      }
      res = `RTSP/1.0 200 OK
Session: ${client.sessionID};timeout=60
CSeq: ${req.headers.cseq}
Cache-Control: no-cache

`.replace(/\n/g, "\r\n");
      return callback(null, res);
    }

    respondAnnounce(socket, req, callback) {
      var ascInfo,
        audioObjectType,
        audioSpecificConfig,
        client,
        j,
        k,
        len,
        len1,
        media,
        nalUnit,
        nalUnitType,
        nalUnits,
        packetizationMode,
        ref,
        ref1,
        ref2,
        res,
        sdpInfo,
        stream,
        streamId;
      // TODO: Refuse uploading to a stream that is being uploaded
      client = this.clients[socket.clientID];
      streamId = RTSPServer.getStreamIdFromUri(req.uri);
      stream = avstreams.get(streamId);
      if (stream != null) {
        stream.reset();
        this.rtpParser.clearUnorderedPacketBuffer(stream.id);
      } else {
        stream = avstreams.create(streamId);
        stream.type = avstreams.STREAM_TYPE_LIVE;
      }
      sdpInfo = sdp.parse(req.body);
      ref = sdpInfo.media;
      for (j = 0, len = ref.length; j < len; j++) {
        media = ref[j];
        if (media.media === "video") {
          sdpInfo.video = media;
          if (
            ((ref1 = media.fmtpParams) != null
              ? ref1["packetization-mode"]
              : void 0) != null
          ) {
            packetizationMode = parseInt(
              media.fmtpParams["packetization-mode"]
            );
            if (packetizationMode !== 0 && packetizationMode !== 1) {
              logger.error(
                `[rtsp:stream:${streamId}] error: unsupported packetization-mode: ${packetizationMode}`
              );
            }
          }
          if (
            ((ref2 = media.fmtpParams) != null
              ? ref2["sprop-parameter-sets"]
              : void 0) != null
          ) {
            nalUnits = h264.parseSpropParameterSets(
              media.fmtpParams["sprop-parameter-sets"]
            );
            for (k = 0, len1 = nalUnits.length; k < len1; k++) {
              nalUnit = nalUnits[k];
              nalUnitType = nalUnit[0] & 0x1f;
              switch (nalUnitType) {
                case h264.NAL_UNIT_TYPE_SPS: // 7
                  stream.updateSPS(nalUnit);
                  break;
                case h264.NAL_UNIT_TYPE_PPS: // 8
                  stream.updatePPS(nalUnit);
                  break;
                default:
                  logger.warn(
                    `unknown nal_unit_type ${nalUnitType} in sprop-parameter-sets`
                  );
              }
            }
          }
        } else if (media.media === "audio") {
          sdpInfo.audio = media;
          if (media.clockRate == null) {
            logger.error(
              "Error: rtpmap attribute in SDP must have audio clock rate; assuming 44100"
            );
            media.clockRate = 44100;
          }
          if (media.audioChannels == null) {
            logger.error(
              "Error: rtpmap attribute in SDP must have audio channels; assuming 2"
            );
            media.audioChannels = 2;
          }
          logger.debug(
            `[${TAG}:client=${client.id}] audio fmtp: ${JSON.stringify(
              media.fmtpParams
            )}`
          );
          if (media.fmtpParams == null) {
            logger.error("Error: fmtp attribute does not exist in SDP");
            media.fmtpParams = {};
          }
          audioSpecificConfig = null;
          ascInfo = null;
          if (
            media.fmtpParams.config != null &&
            media.fmtpParams.config !== ""
          ) {
            audioSpecificConfig = Buffer.from(media.fmtpParams.config, "hex");
            ascInfo = aac.parseAudioSpecificConfig(audioSpecificConfig);
            audioObjectType = ascInfo.audioObjectType;
          } else {
            logger.error(
              "Error: fmtp attribute in SDP does not have config parameter; assuming audioObjectType=2"
            );
            audioObjectType = 2;
          }
          stream.updateConfig({
            audioSampleRate: media.clockRate,
            audioClockRate: media.clockRate,
            audioChannels: media.audioChannels,
            audioObjectType: audioObjectType,
            audioSpecificConfig: audioSpecificConfig,
            audioASCInfo: ascInfo
          });
          if (media.fmtpParams.sizelength != null) {
            media.fmtpParams.sizelength = parseInt(media.fmtpParams.sizelength);
          } else {
            logger.error(
              "Error: fmtp attribute in SDP must have sizelength parameter; assuming 13"
            );
            media.fmtpParams.sizelength = 13;
          }
          if (media.fmtpParams.indexlength != null) {
            media.fmtpParams.indexlength = parseInt(
              media.fmtpParams.indexlength
            );
          } else {
            logger.error(
              "Error: fmtp attribute in SDP must have indexlength parameter; assuming 3"
            );
            media.fmtpParams.indexlength = 3;
          }
          if (media.fmtpParams.indexdeltalength != null) {
            media.fmtpParams.indexdeltalength = parseInt(
              media.fmtpParams.indexdeltalength
            );
          } else {
            logger.error(
              "Error: fmtp attribute in SDP must have indexdeltalength parameter; assuming 3"
            );
            media.fmtpParams.indexdeltalength = 3;
          }
        }
      }
      client.announceSDPInfo = sdpInfo;
      // make circular reference between stream and client
      stream.rtspUploadingClient = client;
      client.uploadingStream = stream;
      client.uploadingTimestampInfo = {};
      socket.isAuthenticated = true;
      res = `RTSP/1.0 200 OK
CSeq: ${req.headers.cseq}

`.replace(/\n/g, "\r\n");
      return callback(null, res);
    }

    respondRecord(socket, req, callback) {
      var client, res, stream, streamId;
      client = this.clients[socket.clientID];
      if (client.mode !== "RECORD") {
        logger.debug(`client mode is not RECORD (got ${client.mode})`);
        res = `RTSP/1.0 405 Method Not Allowed
CSeq: ${req.headers.cseq}

`.replace(/\n/g, "\r\n");
        return callback(null, res);
      }
      streamId = RTSPServer.getStreamIdFromUri(req.uri);
      logger.info(
        `[${TAG}:client=${client.id}] started uploading stream ${streamId}`
      );
      stream = avstreams.getOrCreate(streamId);
      if (client.announceSDPInfo.video != null) {
        this.emit("video_start", stream); // has video
      }
      if (client.announceSDPInfo.audio != null) {
        this.emit("audio_start", stream); // has audio
      }
      res = `RTSP/1.0 200 OK
Session: ${client.sessionID};timeout=60
CSeq: ${req.headers.cseq}
Server: ${this.serverName}
Cache-Control: no-cache

`.replace(/\n/g, "\r\n");
      return callback(null, res);
    }

    respond(socket, req, callback) {
      if (req.protocolName !== "RTSP" && req.protocolName !== "HTTP") {
        // Request cannot be handled; close the connection
        callback(null, null, {
          close: true
        });
      }
      if (
        config.enableRTSP &&
        req.protocolName === "RTSP" &&
        req.method === "OPTIONS"
      ) {
        return this.respondOptions(socket, req, callback);
      } else if (req.method === "POST" && req.protocolName === "HTTP") {
        // HTTP POST
        return this.respondPost(socket, req, callback);
      } else if (req.method === "GET" && req.protocolName === "HTTP") {
        // HTTP GET
        return this.respondGet(socket, req, callback);
      } else if (
        config.enableRTSP &&
        req.protocolName === "RTSP" &&
        req.method === "DESCRIBE"
      ) {
        // DESCRIBE for RTSP, GET for HTTP
        return this.respondDescribe(socket, req, callback);
      } else if (
        config.enableRTSP &&
        req.protocolName === "RTSP" &&
        req.method === "SETUP"
      ) {
        return this.respondSetup(socket, req, callback);
      } else if (
        config.enableRTSP &&
        req.protocolName === "RTSP" &&
        req.method === "PLAY"
      ) {
        return this.respondPlay(socket, req, callback);
      } else if (
        config.enableRTSP &&
        req.protocolName === "RTSP" &&
        req.method === "PAUSE"
      ) {
        return this.respondPause(socket, req, callback);
      } else if (
        config.enableRTSP &&
        req.protocolName === "RTSP" &&
        req.method === "TEARDOWN"
      ) {
        return this.respondTeardown(socket, req, callback);
      } else if (
        config.enableRTSP &&
        req.protocolName === "RTSP" &&
        req.method === "ANNOUNCE"
      ) {
        return this.respondAnnounce(socket, req, callback);
      } else if (
        config.enableRTSP &&
        req.protocolName === "RTSP" &&
        req.method === "RECORD"
      ) {
        return this.respondRecord(socket, req, callback);
      } else {
        logger.warn(
          `[${TAG}] method \"${req.method}\" not implemented for protocol \"${req.protocol}\"`
        );
        return this.respondWithNotFound(req, req.protocolName, callback);
      }
    }

    // Called when received video data over RTSP
    onUploadVideoData(stream, msg, rinfo) {
      var packet;
      if (stream.rtspUploadingClient == null) {
        return;
      }
      //      logger.warn "no client is uploading video data to stream #{stream.id}"
      packet = rtp.parsePacket(msg);
      if (stream.rtspUploadingClient.videoRTPStartTimestamp == null) {
        // TODO: Is it correct to set the start timestamp in this manner?
        stream.rtspUploadingClient.videoRTPStartTimestamp =
          packet.rtpHeader.timestamp;
      }
      if (
        packet.rtpHeader.payloadType ===
        stream.rtspUploadingClient.announceSDPInfo.video.fmt
      ) {
        return this.rtpParser.feedUnorderedH264Buffer(msg, stream.id);
      } else {
        return logger.error(
          `Error: Unknown payload type: ${packet.rtpHeader.payloadType} as video`
        );
      }
    }

    onUploadVideoControl(stream, msg, rinfo) {
      var j, len, packet, packets, results;
      if (stream.rtspUploadingClient == null) {
        return;
      }
      //      logger.warn "no client is uploading audio data to stream #{stream.id}"
      packets = rtp.parsePackets(msg);
      results = [];
      for (j = 0, len = packets.length; j < len; j++) {
        packet = packets[j];
        if (packet.rtcpSenderReport != null) {
          if (stream.rtspUploadingClient.uploadingTimestampInfo.video == null) {
            stream.rtspUploadingClient.uploadingTimestampInfo.video = {};
          }
          stream.rtspUploadingClient.uploadingTimestampInfo.video.rtpTimestamp =
            packet.rtcpSenderReport.rtpTimestamp;
          results.push(
            (stream.rtspUploadingClient.uploadingTimestampInfo.video.time =
              packet.rtcpSenderReport.ntpTimestampInMs)
          );
        } else {
          results.push(void 0);
        }
      }
      return results;
    }

    onUploadAudioData(stream, msg, rinfo) {
      var packet;
      if (stream.rtspUploadingClient == null) {
        return;
      }
      //      logger.warn "no client is uploading audio data to stream #{stream.id}"
      packet = rtp.parsePacket(msg);
      if (stream.rtspUploadingClient.audioRTPStartTimestamp == null) {
        // TODO: Is it correct to set the start timestamp in this manner?
        stream.rtspUploadingClient.audioRTPStartTimestamp =
          packet.rtpHeader.timestamp;
      }
      if (
        packet.rtpHeader.payloadType ===
        stream.rtspUploadingClient.announceSDPInfo.audio.fmt
      ) {
        return this.rtpParser.feedUnorderedAACBuffer(
          msg,
          stream.id,
          stream.rtspUploadingClient.announceSDPInfo.audio.fmtpParams
        );
      } else {
        return logger.error(
          `Error: Unknown payload type: ${packet.rtpHeader.payloadType} as audio`
        );
      }
    }

    onUploadAudioControl(stream, msg, rinfo) {
      var j, len, packet, packets, results;
      if (stream.rtspUploadingClient == null) {
        return;
      }
      //      logger.warn "no client is uploading audio data to stream #{stream.id}"
      packets = rtp.parsePackets(msg);
      results = [];
      for (j = 0, len = packets.length; j < len; j++) {
        packet = packets[j];
        if (packet.rtcpSenderReport != null) {
          if (stream.rtspUploadingClient.uploadingTimestampInfo.audio == null) {
            stream.rtspUploadingClient.uploadingTimestampInfo.audio = {};
          }
          stream.rtspUploadingClient.uploadingTimestampInfo.audio.rtpTimestamp =
            packet.rtcpSenderReport.rtpTimestamp;
          results.push(
            (stream.rtspUploadingClient.uploadingTimestampInfo.audio.time =
              packet.rtcpSenderReport.ntpTimestampInMs)
          );
        } else {
          results.push(void 0);
        }
      }
      return results;
    }
  };

  // Represents an RTSP session
  RTSPClient = class RTSPClient {
    constructor(opts) {
      var name, value;
      this.videoPacketCount = 0;
      this.videoOctetCount = 0;
      this.audioPacketCount = 0;
      this.audioOctetCount = 0;
      this.isPlaying = false;
      this.timeoutID = null;
      this.videoSSRC = generateRandom32();
      this.audioSSRC = generateRandom32();
      this.supportsReliableRTP = false;
      for (name in opts) {
        value = opts[name];
        this[name] = value;
      }
    }

    disablePlaying() {
      if (this.useHTTP) {
        this.getClient.isWaitingForKeyFrame = false;
        return (this.getClient.isPlaying = false);
      } else {
        this.isWaitingForKeyFrame = false;
        return (this.isPlaying = false);
      }
    }

    enablePlaying() {
      if (this.useHTTP) {
        if (
          ENABLE_START_PLAYING_FROM_KEYFRAME &&
          client.stream.isVideoStarted
        ) {
          return (this.getClient.isWaitingForKeyFrame = true);
        } else {
          return (this.getClient.isPlaying = true);
        }
      } else {
        if (ENABLE_START_PLAYING_FROM_KEYFRAME && stream.isVideoStarted) {
          return (this.isWaitingForKeyFrame = true);
        } else {
          return (this.isPlaying = true);
        }
      }
    }

    toString() {
      var ref, transportDesc;
      if (this.socket.remoteAddress == null) {
        return `${this.id}: session=${this.sessionID} (being destroyed)`;
      } else {
        transportDesc =
          this.clientType != null ? `type=${this.clientType}` : "";
        if (
          (ref = this.clientType) === "http-get" ||
          ref === "tcp" ||
          ref === "udp"
        ) {
          transportDesc += ` isPlaying=${this.isPlaying}`;
        }
        return `${this.id}: session=${this.sessionID} addr=${this.socket.remoteAddress} port=${this.socket.remotePort} ${transportDesc}`;
      }
    }
  };

  api = {
    RTSPServer: RTSPServer,
    INTERLEAVED_SIGN: 0x24, // '$' (dollar sign)
    INTERLEAVED_HEADER_LEN: 4,
    // Creates an interleaved header and returns the buffer.

    // opts:
    //   channel: <number> channel identifier
    //   payloadLength: <number> payload length
    createInterleavedHeader: function(opts) {
      if ((opts != null ? opts.channel : void 0) == null) {
        throw new Error("createInterleavedHeader: channel is required");
      }
      if ((opts != null ? opts.payloadLength : void 0) == null) {
        throw new Error("createInterleavedHeader: payloadLength is required");
      }
      return Buffer.from([
        api.INTERLEAVED_SIGN,
        opts.channel,
        opts.payloadLength >> 8,
        opts.payloadLength & 0xff
      ]);
    },
    // Parses and returns an interleaved header.

    // If the buffer doesn't have enough length for an interleaved header,
    // returns null.
    parseInterleavedHeader: function(buf) {
      var info;
      if (buf.length < api.INTERLEAVED_HEADER_LEN) {
        // not enough buffer
        return null;
      }
      if (buf[0] !== api.INTERLEAVED_SIGN) {
        throw new Error("The buffer is not an interleaved data");
      }
      info = {};
      info.channel = buf[1];
      info.payloadLength = (buf[2] << 8) | buf[3];
      info.totalLength = api.INTERLEAVED_HEADER_LEN + info.payloadLength;
      return info;
    },
    // Parses and returns the information of complete interleaved data.

    // If parsing failed or buf doesn't have enough length for
    // the payload, returns null.
    getInterleavedData: function(buf) {
      var info;
      info = api.parseInterleavedHeader(buf);
      if (info == null) {
        return null;
      }
      if (buf.length < info.totalLength) {
        // not enough buffer
        return null;
      }
      info.data = buf.slice(api.INTERLEAVED_HEADER_LEN, info.totalLength);
      return info;
    },
    isLoopbackAddress: function(socket) {
      return socket.remoteAddress === "127.0.0.1";
    },
    // Check if the remote address of the given socket is private
    isPrivateNetwork: function(socket) {
      var match, num;
      if (/^(10\.|192\.168\.|127\.0\.0\.)/.test(socket.remoteAddress)) {
        return true;
      }
      if ((match = /^172.(\d+)\./.exec(socket.remoteAddress)) != null) {
        num = parseInt(match[1]);
        if (16 <= num && num <= 31) {
          return true;
        }
      }
      return false;
    },
    getDateHeader: function() {
      var d;
      d = new Date();
      return (
        `${DAY_NAMES[d.getUTCDay()]}, ${d.getUTCDate()} ${
          MONTH_NAMES[d.getUTCMonth()]
        }` +
        ` ${d.getUTCFullYear()} ${zeropad(2, d.getUTCHours())}:${zeropad(
          2,
          d.getUTCMinutes()
        )}` +
        `:${zeropad(2, d.getUTCSeconds())} UTC`
      );
    },
    // Returns this machine's IP address which is attached to network interface
    // TODO: Get IP address from socket
    getLocalIP: function() {
      var addr,
        getPriority,
        ifaceName,
        ifaceNames,
        ifacePrecedence,
        ifaces,
        j,
        k,
        len,
        len1,
        ref;
      ifacePrecedence = ["wlan", "eth", "en"];
      // compare function for sort
      getPriority = function(ifaceName) {
        var i, j, len, name;
        for (i = j = 0, len = ifacePrecedence.length; j < len; i = ++j) {
          name = ifacePrecedence[i];
          if (ifaceName.indexOf(name) === 0) {
            return i;
          }
        }
        return ifacePrecedence.length;
      };
      ifaces = os.networkInterfaces();
      ifaceNames = Object.keys(ifaces);
      ifaceNames.sort(function(a, b) {
        return getPriority(a) - getPriority(b);
      });
      for (j = 0, len = ifaceNames.length; j < len; j++) {
        ifaceName = ifaceNames[j];
        ref = ifaces[ifaceName];
        for (k = 0, len1 = ref.length; k < len1; k++) {
          addr = ref[k];
          if (!addr.internal && addr.family === "IPv4") {
            return addr.address;
          }
        }
      }
      return "127.0.0.1";
    },
    getExternalIP: function() {
      return "127.0.0.1"; // TODO: Fetch this from UPnP or something
    },

    // Get local IP address which is meaningful to the
    // partner of the given socket
    getMeaningfulIPTo: function(socket) {
      if (api.isLoopbackAddress(socket)) {
        return "127.0.0.1";
      } else if (api.isPrivateNetwork(socket)) {
        return api.getLocalIP();
      } else {
        return api.getExternalIP();
      }
    },
    leaveClient: function(client) {
      var ref, stream, streamName;
      ref = avstreams.getAll();
      for (streamName in ref) {
        stream = ref[streamName];
        logger.debug(`[stream:${stream.id}] leaveClient: ${client.id}`);
        if (stream.rtspClients[client.id] != null) {
          delete stream.rtspClients[client.id];
          stream.rtspNumClients--;
        }
      }
    }
  };

  module.exports = api;
}.call(this));
